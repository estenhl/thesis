\documentclass[thesis.tex]{subfiles}

\begin{document}
\chapter{Future work}
\label{ref:future_work}
\section{Improvements of the algorithm}
We have chosen to divide the needed work on the tool into three levels, depending on the level of abstraction of the involved elements. The first level could be called something like \textit{``Changes needed to make the tool usable for solving a biological problem''} and includes things such as implementing support for looking up reverse-complementary strings. However, this level also includes things which are extremely problem-specific regarding which direction the developer want to take: Maybe you want to store the origins of vertices or edges. Due to the subjectivity this level is not discussed in great detail.\\
\par\noindent
The second level concerns \textit{``Stuff which is so badly implemented it needs fixing to make usage of the tool feasible''}. The stand-out element on this level is the indexation process. This requires some more work. The index has to be flexible enough to handle fuzzy searches on dense, often extremely similar data-sets. Inspiration could be taken from the work on suffix structures for regular strings\textcolor{red}{[ref]} or possibly from the broader realm of Information Retrieval\textcolor{red}{[ref]}. Another element on this level is the parallellization. Including a smart parallellization procedure into the actual suffix tree search could have a dramatic impact on runtimes. These two elements should be combined by having parallellization in the back of the mind while redesigning the index structure. It could also be possible to implement parallellization on the second step of the algorithm using some sort of Future-objects, although this seems a taller mountain to climb for a smaller reward.\\
\par\noindent
The third and final level contains \textit{``Elements which can possibly be improved to drastically reduce runtimes''}. At this level we examine the conceptual algorithm and try to identify possibly unecessary double-work being done. The first thing which stand out as such is the usage of paths as contexts to determine which vertices should be used, then taking a step back down to the vertex-level to find recombinations of paths used for the alignment. This is completely necessary in the approach presented here to ensure flexibility as far as possible, but feels like an excessive step back and forth. Finding a better solution for this could improve the complexity of both steps of algorithms by reducing the number of individual vertices searched for in the suffix tree search which also reduces the complexity of the generated graph for the dynamic programming search.\\
\par\noindent
Secondarily, this approach feeds all candidate vertices found by pruning into a single graph. This seems unnecessary as the candidate vertices could stem from regions of the graph which are both interesting, but they are so far apart there can exist no combination of them which is interesting. If these cases could be determined efficiently the vertices could be split up into two candidate graphs which for instance can be searched in parallell. The main problem would be determining when this is the case without too much overhead.
\section{Further testing}
The second part of interesting further work would be to go further to determine whether the approach is feasible in actual biological settings. Preferably this should be done after the work discussed in the previous section, but early testing could provide valuable insights on whether the approach is even tractable as a solution to the problems presented in this thesis. This testing should be done on actual computers doing these kinds of operations using real-life, large data-sets. In this situation we also imagine an improvement to the visualization of the graphs could prove useful.
\end{document}