\documentclass[thesis.tex]{subfiles}

\begin{document}
\chapter{The algorithm ``Fuzzy context-based search''}
{\parindent0pt
In this chapter we introduce the algorithm ``Fuzzy context-based search'' as a solution to the problem of aligning text strings against graph-based reference genomes. In order to do this we will first present formal definitions of the elements and structures involved aswell as the problem itself. The following description of the algorithm will be a conceptual overview where the motivation behind the steps taken are also described. A more detailed introduction to an implementation of the algorithm will follow in the succeeding chapter, in which space and time complexity will also be discussed. Due to the abstract nature of this chapter the reader is advised to use the coming chapter as a reference whenever needed. The two have corresponding sections, and the latter contain exact details and concrete examples.\\
\par\noindent
In order to avoid ambiguity when dealing with already existing concepts, the terms which are defined are given problem-specific names. For several of the terms there also follows a shorthand notation behind the original name in the definition title. Whenever these shorthand names are used in the subsequent explanatory sections we refer exclusively to the definitions done in this thesis.
\section{The graphs}
The graphs used as reference genome graphs will be built iteratively by starting out with an empty graph and sequentially merging in input sequences aligned against the existing structure. How the sequences are merged, and thus what the graphs look like, are decided entirely through the alignment procedure, which in part relies on the scoring schema. This first section is dedicated to precisely defining the involved graphs. 
\begin{defn}[Graph-based reference genome (Graph)]
  A pair $G=\{V,E\}$ where $V$ is a set of vertices and $E$ is a set of edges. $|G|$ denotes the number of vertices in $G$.
\end{defn}
The involved graphs will be sequence graphs (Section \ref{sec:sequence_graphs}) where every vertice correspond to a single nucleotide from a one or more input sequences used in building the graph. Whether the vertice originates from a single or several sequences is based on whether any new bases has been mapped, and consecutively merged into the vertice. In addition to the nucleobase the vertices will contain an index which is unique to the graph. Every graph $G$ will have two special vertices $s_G=\{s, 0\}$ and $t_G=\{e, -1\}$ which represents unique start and end vertices. 
\begin{defn}[Graph genome vertice (Vertice)]
  A pair $v=\{b, i\}$ where $b \in \{A, C, T, G\}$ and $i$ is a unique index. The vertice at index $i$ is denoted $v_i$. The notation $b(v_i)$ references the first element in the pair (the nucleotide).
\end{defn}
The edges model the relationships between the vertices and thus the relationships between the elements of the input sequences. Every edge has its origin from a consecutive pair of nucleotides in one or more input sequences.
\begin{defn}[Graph genome edge (Edge)]
  An ordered pair $e=\{i_s, i_e\}$ where both elements are indexes for vertices. 
\end{defn}
There exists no information storing the origin of an edge, or whether an edge originates from one or more input sequences, and all edges are thus seen as equally probable when aligning a sequence. A sequence of vertices where there exists an edge for every pair of consecutive vertices is called a \textit{path}. The introduction of paths is a a way of capturing the combination of several individual characters into text strings in the domain of our graphs.
\begin{defn}[Graph genome path (Path)]
  A list $P$ of indexes such that for all consecutive pairs $p_x, p_{x+1}\ \in P$, where $p_n$ denotes the n-th element of the list, there exists an edge $e=\{p_x, p_{x+1}\}$. The notation $p_{-1}$ denotes the last element in the list. The length of $P$, $l(P)$, is equal to the number of indexes in the list. The distance $d(P)$ between $p_0$ and $p_{-1}$ is $l(P) - 2$.
\end{defn}
\begin{corollary}
  Every edge $e$ is also a path $P$ with $l(P)=2$ and $d(P)=0$.
\end{corollary}
Paths spanning the entire length of a graph $G$, from $s_G$ to $t_G$ are named full paths. Every input sequence used to build the graph has a corresponding full path.
\begin{defn}[Full path]
  A path $P$ through a graph $G$ where $p_0=0$ and $p_{-1}=-1$
\end{defn}
There is no correspondence the other way, meaning there can exist full paths which does not originate from a single input sequence (Fig. \ref{fig:example_reference}). When aligning regular text strings against eachother the introduction of gaps is a key element. The concept of strings with gaps are translated to graphs through \textit{incomplete paths}.
\begin{defn}[Incomplete path]
  A list $P*$ of indexes such that for all consecutive pairs $\{p*_x, p*_{x+1}\} \in P*$ there exists a path $P$ such that $p_0=p*_x$ and $p_{-1}=p*_{x+1}$.
\end{defn}
Conceptually incomplete paths can be seen as regular paths where some of the vertices are removed to reflect gaps. We can score an incomplete path by looking solely at the gaps present and avoiding the nucleobases contained in the vertices to produce a \textit{path score}. 
\begin{defn}[Path score]
  The total score of all gaps present in an incomplete path $P*$ according to a scoring schema
\end{defn}
In an incomplete path there exists two possible relationships between consecutive elements: Either they are neighbours and there exists an edge between them, or they are not neighbours and are at the beginning and end of a path. Because the edges have distance $0$ and are thus not penalized, the path score of an incomplete path can be found by summarizing gap penalties for gaps between every pair of consecutive vertices.
\begin{corollary}
  $pathScore(P*)=\Sigma^{|P*|-2}_{i=0} gapPenalty(distance(p*_i, p*_{i+1}))$ where $distance(x, y)$ denotes the distance of the shortest path $P$ where $P_0=x$ and $P_{-1}=y$.
\end{corollary}
\begin{figure}[t]
  \begin{mdframed}
    \begin{center}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.4cm,scale=0.5]
        \node[state,align=center] (q0) {$s$\\ \scriptsize{0}};
        \node[state,align=center] [right of=q0] (q1) {$A$\\ \scriptsize{1}};
        \node[state,align=center] [above right=0.6cm and 0.63cm of q1] (q2) {$T$\\ \scriptsize{2}};
        \node[state,align=center] [right of=q1] (q3) {$G$\\ \scriptsize{6}};
        \node[state,align=center] [below right=0.6cm and 0.63cm of q1] (q4) {$C$\\ \scriptsize{8}};
        \node[state,align=center] [right of=q3] (q5) {$A$\\ \scriptsize{3}};
        \node[state,align=center] [above right of=q5] (q6) {$T$\\ \scriptsize{4}};
        \node[state,align=center] [below right of=q5] (q7) {$G$\\ \scriptsize{7}};
        \node[state,align=center] [below right of=q6] (q8) {$A$\\ \scriptsize{5}};
        \node[state,align=center] [right of=q8] (q9) {$e$\\ \scriptsize{-1}};

        \path
        (q0) edge node {} (q1)
        (q1) edge node {} (q2)
        edge node {} (q3)
        edge node {} (q4)
        (q2) edge node {} (q5)
        (q3) edge node {} (q5)
        (q4) edge node {} (q5)
        (q5) edge node {} (q6)
        edge node {} (q7)
        edge node {} (q8)
        (q6) edge node {} (q8)
        (q7) edge node {} (q8)
        (q8) edge node {} (q9);
      \end{tikzpicture}
    \end{center}
  \end{mdframed}
  \caption{An example reference graph $G$ made from the three sequences ``ATATA'', ``AGAGA'' and ``ACAA''. Although the graph is made from 3 sequences, 9 full paths can be found}
  \label{fig:example_reference}
\end{figure}
}
\clearpage
\section{The alignment problem}
{\parindent0pt
Because the alignment problem is concerned with aligning text strings against graphs we need to define a second component alogngside the graphs: The input sequences.
\begin{defn}[Input sequence]
  A string $s$ over the alphabet $\{A, C, T, G\}$. The length of the string is given by $|s|$. The individual character on position $0<=x<|s|$ is referenced by $s_x$
\end{defn}
Once we have a clear definition of a graph $G$ and an input sequence $s$ we can try to find an \textit{alignment} between the two, which model the relationship between them. In order to do this, the alignments should provide relations between the smallest constituents of the two input structures, the vertices of the graph and the characters of the string, in a way such that the interal structures of the two are reflected against eachother. We can model an alignment as a special variant of an incomplete path, which allows for \textit{unmapped elements}. These elements are recognized as elements of $|s|$ which is mapped to $0$, the index of the start-vertice and thus always an invalid mapping. The remaining elements of $s$ is mapped to indexes of valid vertices of $G$ which form an incomplete path $P*$. Moving forward through the individual positions $s_x$ which are mapped corresponds to traversing $P*$.
\begin{defn}[Alignment]
  Given a graph $G$ and a string $s$, an alignment $A$ is an ordered list of length $|s|$ such that every element $a_x \in A$ is either $0$ or the index for a valid vertice of $G$ such that for every consecutive pair of valid indexes $a_n, a_m$ there exists a path $P$ where $p_0=a_n$ and $p_{-1}=a_m$. A $0$ represents an unmapped character in $s$.
\end{defn}
When we have defined the alignments we can start scoring them. The scoring happens according to a scoring schema and should be the sum of three different scores:
\begin{enumerate}
  \item The mapping scores of the mapped elements
  \item The gap penalties for gaps in the graph, represented by the distance of the shortest path between consecutive pairs of mapped elements
  \item The gap penalties for gaps in the string, represented by unmapped positions
\end{enumerate}
We already know how to find the first two. The last can be found by summing up the gap penalties for all the gaps in the input sequence. A gap in the input sequence can be identified by a continuous subsequence $A*_{x:y} \in A$ spanning the indexes $x$ to $y-1$ where every element is unmapped. An important aspect here is that every unmapped element should only be considered part of exactly one gap. We cover this aspect by only considering \textit{maximal unmapped subsequences}
\begin{defn}
  A subsequence $A*_{x:y} \in A$, such that every $a*=0$ for every $a* \in A*$ and $x$ is either $0$ or $a_{x-1} \neq 0$ and $y$ is either $|s|-1$ or $a_{y+1} \neq 0$.
\end{defn}
The gap penalties for gaps in the string is then defined as $\Sigma_{A* \in A} gapPenalty(|A*|)$ where $A*$ is the maximal unmapped subsequences of $A$.
\begin{defn}[Alignment score]
  Given a sequence $s$, a graph $G$ and an alignment $A$, the score produced by combining mapping scores for the pairs $\{b(v_{a_x}), s_x\} for 0<=x<|s|$ with the path score for the incomplete path provided by consecutive mapped indexes of $A$ and the gap penalties for the string gaps in $A$. We reference this score by $alignmentScore(A)$.
\end{defn}
We can then easily define the alignment problem itself:
\begin{defn}[The optimal alignment score problem]
  For any pair $\{G, s\}$, where $G$ is a graph and $s$ is an input sequence, find one of the alignments $A$ which produces the highest possible alignment score.
\end{defn}
Notice that the definition only calls for finding one of the alignments which produce a highest possible score. This is done in order to simplify the abstract explanations of the algorithm. Implementation-wise this can trivially be changed to find all optimal alignments. The necessary adjustments is discussed as a part of the succeding chapter in section \ref{sec:all_optimal_alignments}. Additionally we have defined a bounded version of the problem, called \textit{The bounded optimal alignment score problem}. This second version also considers a score threshold value $T$ and deems a string $s$ \textit{unalignable} if the optimal alignment produces a score lower than T.
\begin{defn}[The bounded optimal alignment score problem]
  \label{def:bounded_alignment_problem}
  Given a triplet $\{G, s, T\}$ where $G$ and $s$ are as before and $T$ is a numeric value, find the alignment $A$ which produces the highest alignment score, if and only if the alignment score for $A$ is higher than $T$. If no such alignment exists, $s$ should be classified as unalignable.
\end{defn}
Defining a bounded adaptation of the problem is obviously done in order to reduce the computational complexity, but it also present a powerful notion of control to the model: We can choose the degree of similarity required for elements to be considered equal. This simplifies the concept of equality into a classification problem where the border between the two classes can be easily manipulated through the threshold variable.
}
\clearpage
\section{``Fuzzy context-based search''}
We now present the algorithm we propose as a solution to the bounded optimal alignment score problem. The algorithm consists of two distinct subproblems which are solved in consecutive steps:
\begin{enumerate}
  \item Create a new graph $G'$ for an input triplet $\{G, s, T\}$
  \item Search $G'$ for an optimal alignment
\end{enumerate}
Both the motivation behind each step and the conceptual approach for solving the subproblem will be explained in its corresponding subsection. In addition to the three involved components set as input parameters, the algorithm has a preset scoring schema.\\
\par\noindent
In presenting the algorithm we introduce a new variable $\lambda$. $\lambda$ represents the \textit{error margin} allowed in an alignment and is computed by taking the difference between the highest possible alignment score for $s$ and the scoring threshold $T$. The highest possible score for any string can be found by aligning the string against itself with regular string alignment operations, using the already defined scoring schema. Introducing $\lambda$ gives us the opportunity to do strict pruning throughout the entire alignment process: Any alignment which contains a single element, be it a gap or a sequence of mappings, which is penalized more than $\lambda$ compared to the corresponding element in an optimal alignment can never have a total alignment score higher than $T$ (This should hopefully become apparent throughout this chapter, but a more compact proof can be found in Appendix \ref{sec:proof}).
\subsection{Creating a new graph}
The motivation behind building an entirely new graph is the realization that whenever reads are mapped against a reference genome the read is typically vastly shorter than the reference. We can therefore do a \textit{horizontal pruning} where we determine which sections along the horizontal axis of the graphs are interesting for the alignment. The same argument can be made for extremely complex graphs, where only a small number of the branches are relevant, in an operation we have called a \textit{vertical pruning}. The result should be a new graph $G'$ with a vertice set $V'$ and an edge set $E'$.\\
\par\noindent
We first let $V'$ be a subset of the original vertice set $V$. In order to guarantee optimality we put a restriction on $V'$:
\begin{enumerate}
  \item Every $v_x \in V$ should be in $V'$ if there exists an optimal alignment $A$ with a higher score than $T$ which contains the index $x$
\end{enumerate}
Through the definition of the alignments we know they are ordered and that the indexed elements refer to the vertices which map to a specific position in the string. We can use this knowledge to more specifically define $V'$ as an ordered set of sets $V'_x$ where every indexed set is related to the corresponding position in the alignment:
\begin{enumerate}
  \item Every $v_x \in V$ should be in $V'_y$ if there exists an optimal alignment $A$ with a higher score than $T$ where $a_y=x$
\end{enumerate}
This is a restriction which is strictly enforced throughout the algorithm, to continue ensuring the optimal solution is still a possibility. We formulate a second restriction, to reduce the number of vertices which are not interesting for final alignments:
\begin{enumerate}
  \setcounter{enumi}{1}
  \item Every vertice $v_x \in V$ which is not referenced by $a_i$ in any optimal alignment should not be in $V'_i$
\end{enumerate}
If we manage to create $V'$ from these two restrictions we can guarantee a vertice set where every element of every optimal alignment is still present and all excesses vertices has been dropped. However, finding these vertices requires knowledge of every alignment $A$ of every string $s$ for every threshold $T$, a number of possibilities which quickly become infeasible. In order to make the operation more tractable we identify the second restriction as only being related to the computational complexity, which means it does not have to be strictly enforced. We can thus relax it:
\begin{enumerate}
  \setcounter{enumi}{1}
  \item Every vertice $v_x \in V$ should be in $V'_i$ for every $0<=i<|s|$.
\end{enumerate}
This is a complete relaxation and puts every vertice $v \in V$ in every subset of $V'$. The resulting parenting candidate vertice set $V'$ is a set far greater than $V$ which is obviously suboptimal for the following search. These two cases represent the two extremes on the scale of how strictly we enforce the second restriction and they both represent problems: Either the search is too hard to the results are not good enough. We can let the second restriction be an informal description of a search for an optimal middle ground between the two:
\begin{enumerate}
  \setcounter{enumi}{1}
  \item Every subset $V'_x$ should be \textit{as small as possible, without being the search growing too complex}
\end{enumerate}
We let a vertice $v$ be a \textit{candidate vertice} for index $i$ if it is a part of the \textit{candidate set} $V'_i$. In order to find candidate vertices we apply \textit{fuzzyness} to the context-based mapping schema proposed by Paten et al.\cite{mapping_to_a_reference_genome_structure}. We say a vertice is a candidate vertice for an index if it has a context which is similar enough to the context of the corresponding position in $s$. The vagueness of ``similar enough'' is controlled through the fuzzyness, which again is controlled through the error margin parameter $\lambda$. The contexts of the vertice represents the paths passing through it, and because we know that if a context is penalized more than $\lambda$ compared to the maximal possible score we know that the context can never be a part of a longer incomplete path with a total score higher than $T$. Thus, more formally, for every index $0<=i<|s|$ we put $v_x$ in $V'_i$ if and only if the context set $c(v_x)$ of $v_x$ contains a context which can be aligned against $c(s_i)$ with a score higher than $T_c$. $T_c$ is a \textit{context threshold score} and is computed by taking the max possible score for a context in $s$ and subtract $\lambda$.\\
\par\noindent
After deciding which vertices make up $G'$ we need to decide how we combine them, through the edge set $E'$. Because the subsets of candidate vertices follow a natural ordering there is already defined a direction in the graph. Every vertice of every candidate set $V'_i$ should have an incoming edge from every vertice in the preceding candidate set $V'_{i-1}$ to account for this direction. Because we allow gaps in our alignments we have to extend the number of steps a vertice looks back for possible paths: Every vertice in every candidate set $V'_i$ should have an incoming edge from \textit{every} preceding candidate set $V'_{j}$, where $0<=j<i$. These edges represent the relationships between the elements of the string. We do also want to represent the relationships between the vertices in the graph they originate from. This is done through introducing \textit{weighted edges}:
\begin{defn}[Graph genome weighted edge (Weighted edge)]
  A triplet $e'=\{i_s, i_e, w\}$ where the two first elements are indexes for vertices in $V'$ and the latter is an integer value
\end{defn}
We let the weight $w$ denote the distance $d(P)$ of the shortest path $P$ where $P_0=i_s$ and $P_{-1}=i_e$. These weights can be found through a regular graph search in $G$, if no distance is found we let it be $\inf$. At this point we have a complete graph $G'$.
\begin{corollary}
  For every edge $e=\{i_s, i_e\} \in E$ where $v_{i_s} \in V'_x, v_{i_e} \in V'_y$ and $x>y$ there exists a weighted edge $e'=\{i_s, i_e, 0\} \in E'$
\end{corollary}
\noindent
The resulting graph is still very complex . Every vertice is connected to every preceding vertice, and in order to find the weights of these edges we need to do graph searches for every possible pair of vertices. However, we still know we are not interested in incomplete paths which have a lower score than $T$ and we thus can limit the edges to only the ones that are passable without being penalized more than $\lambda$. This sets a bound both on how far back in the candidate sets a vertice looks for neighbours and, more importantly, puts a strict upper bound on the complexity of the individual graph searches done in $G$.
\subsection{Searching the newly formed graph}
We have built $G'$ in a specific way to guarantee the optimal alignments still exist, which means the next step is finding them. Searching for an alignment means combining vertices, representing bases, into a path representing a string. This linear sequence can be aligned against the input sequence with regular string alignment tools and the scores are therefore easily verifiable.\\
\par\noindent
In order to continue securing optimal results the algorithm does the search using dynamic programming. The search algorithm is conceptually very similar to PO-MSA\cite{multiple_sequence_alignment_using_partial_order_graphs}, except the roles are switched around: Instead of searching through the reference graph with an input string we are searching through the indices of the string with the canditate nodes from the reference graph as our input. When we dynamically compute scores we are still doing the same thing as a regular PO-MSA, letting a candidate vertice $v_x$ in a candidate set $V'_i$ be an intersection at position $x, i$ in a two-dimensional space where the dimensions represent the string and the path. We set the scores to the highest possible score for aligning the substring $s'_i$ of $s$ ending in $i$ against a path ending in $v_x$. In this way we can find the highest possible score for the entire alignment in the highest scoring node in the last candidate set.\\
\par\noindent
The base case of the dynamic programming are the candidate vertices in the first candidate set, $v_x \in V'_0$. We initialize these scores to $mappingScore(b(v_x), s_0)$, which is equivalent to aligning them against the substring containing exactly the first character of the string. During the following bottom-up procedure we will be faced with another set of base cases: Vertices which have no incoming edges. If the vertices are reachable by gapping over the preceding indexes of the string without the gap penalty exceeding $\lambda$ we initialize them to their mapping score combined with the gap penalty. In all other cases we set the score to $-2 * \lambda$, which yields any path starting with the vertice score lower than $T$ and thus not be considered candidates for the optimal alignment.\\
\par\noindent
The recurrence relation of the dynamic programming algorithm is concerned with setting the score for any vertice/index pair which is not a base case. The score for these candidate vertices $v_x \in V'_i$ are set by looking at all incoming edges, find the one yielding the highest score and add $mappingScore(b(v_x), s_y)$. The score for an edge is found by taking the score in the vertice $v_y \in V'_j$,represented by the start-index $i_s$ in the edge, and adding the gap penalties corresponding to traversing the edge. There are two gap penalties related to the edge: one penalty for the distance represented by the weight $w$ and one penalty for jumping from index $i$ to index $j$. However, all edges traversed in the final alignment will only be penalized for one of them.\\
\par\noindent
When the scores have been computed for every candidate vertice we can start looking for the highest score, which represents the alignment score for one of the optimal alignments. We will find this score in as a score for one of the vertices in the candidate set corresponding to the last index of the string. At this point we just have to backtrack the procedure which lead to the score to find the actual alignment, which is guaranteed to be one of the optimal alignments. If we find no score which is higher than the threshold $T$ in this column we can deem the string as unalignable.
\section{Heuristical applications}
This chapter presents a non-heuristical algorithm which is never incorrect, a concept which provides steady ground when discussing the tractability of a conceptual solution to a problem. The rest of the thesis will be concerned with the algorithm explained here, in all its formally provable glory. However we at this point want to take a brief detour to discuss heuristical applications, and more specifically the heuristical possibilities provided by the presented approach. Whenever we do not find any possible paths we can align against to achieve a score higher than $T$ we do a hard cut-off and deem $s$ unalignable, to achieve the previously mentioned formally steady ground. This might seem a bit rash: We have already done searches to determine which parts of $G$ are similar to parts of $s$. The results from these searches could be utilized to for instance ``lock in'' some areas of $s$. Then the remainder of the alignment could be pieced together by filling in the gaps. Doing this would result in something similar to the approach presented in section \ref{sec:canonical}. Thus, the comparison between the two found in section \ref{sec:comparison_discussion} will also cover many of the implications of a strict non-heuristical approach vs. an heuristic. 
\end{document}