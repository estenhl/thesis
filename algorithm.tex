\documentclass{article}

\begin{document}
\chapter{Algorithm}
In this section I will present the algorithm ``Fuzzy context-based search'' as an approach for mapping text strings against graph-based reference genomes. First the elements involved will be described in order to precisely define the problem. Then the syntax of the reference graphs used are explained in more detail. Finally, the algorithm is presented both through a conceptual overview and in more specific detail. The implementation details refers to the tool \textit{Graph Genome Alignment} (See Supplementary XXX).
\section{Definitions}
\begin{defn}[Graph-based reference genome (graph)]
  A pair $G=\{V,E\}$ where $V$ is a set of vertices and $E$ is a set of edges. $|G|$ denotes the number of vertices of $G$.
\end{defn}
\begin{defn}[Vertice]
  A pair $v=\{b, i\}$ where $b \in \{A, C, T, G\}$ and $i$ is a unique index. Every graph $G$ also has two special vertices $s_G=\{s, 0\}$ and $t_G=\{e, -1\}$ which represents unique start and end vertices.
\end{defn}
\begin{defn}[Edge]
  An ordered pair $e=\{i_s, i_e\}$ where both elements are indexes for vertices. 
\end{defn}
\begin{defn}[Complete Path]
  An ordered list $P$ of indexes such that for all consecutive ordered pairs $\{i_x, i_{x+1}\} \in P$ there exists an edge $e=\{i_x, i_{x+1}\}$.
\end{defn}
\begin{defn}[Path]
  An ordered list $L$ of indexes such that for all consecutive ordered pairs $\{i_x, i_{x+1}\} \in L$ there exists a complete path $P$ which starts at $\{i_x\}$ and ends at $i_{x+1}\}$.
\end{defn}
\begin{defn}[Input sequence]
  A string $s$ over the alphabet $\{A, C, T, G\}$. The length of the string is given by $|s|$. An individual character on position $x$ is referenced by $s_x$
\end{defn}
\begin{defn}[Mapping score]
  A score produced by mapping two characters $c_1, c_2 \in \{A, C, G, T\}$ against a scoring matrix
\end{defn}
\begin{defn}[Path score]
  A score produced by traversing a path $P$ through a graph $G$ to create a linear sequence, scoring gaps according to the gap penalties given by a scoring schema.
\end{defn}
\begin{defn}[Alignment]
  Given a sequence $s$ and a graph $G$, an ordered list $A$ of indexes such that every $a_x \in A$ is either a valid index for a vertice in $G$ or $0$. $0$ indicates an unmapped element of the input sequence
\end{defn}
\begin{defn}[Alignment score]
  Given a sequence $s$, a graph $G$ and an alignment $A$, the score produced by combining mapping scores for the pairs $\{a_x, s_x\} for 0<=x<|s|$ with the path score for the path(s) provided by $A$ aligned against both $G$ and $s$.
\end{defn}
\begin{defn}[The optimal alignment score problem]
  For any pair $\{G, s\}$, where $G$ is a graph and $s$ is a sequence, find the alignment $A$ which produces the highest possible alignment score.
  \textcolor{red}{If multiple max scores: Provide all or chose one?}
\end{defn}
\begin{defn}[The bounded optimal alignment score problem]
  Given a triplet $\{G, s, T\}$ where $G$ and $s$ are as before and $T$ is a numeric value, find the alignment $A$ which produces the highest alignment score, iff the score for $A$ is higher than $T$. If no such alignment exists, $s$ is unmappable.
\end{defn}
\section{The graph}
As defined the graphs involved will be graphs where one vertice represents a single nucleotide. Every vertice also contains an identifying index, which maps uniquely to that vertice. A graph $G$ is made by starting out with only the start and end vertices, and iteratively merging in new sequences. Every sequence merged into the graph has a corresponding path starting in $s_G$ and ending in $t_G$. There is no correspondence the other way, meaning there can be complete paths from $s_G$ to $t_G$ which does not originate from a single sequence (See fig. \ref{fig:example_reference}). There exists no information storing the origin of an edge and all paths are thus seen as equally probable when aligning a sequence. How the new sequences are merged is defined entirely through the alignment procedure which relies in part on the scoring threshold $\lambda$ and the given scoring schema.
\clearpage
\begin{figure}
  \begin{mdframed}
    \begin{center}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.4cm,scale=0.5]
        \node[state,align=center] (q0) {$s$\\ \scriptsize{0}};
        \node[state,align=center] [right of=q0] (q1) {$A$\\ \scriptsize{1}};
        \node[state,align=center] [above right=0.6cm and 0.63cm of q1] (q2) {$T$\\ \scriptsize{2}};
        \node[state,align=center] [right of=q1] (q3) {$G$\\ \scriptsize{6}};
        \node[state,align=center] [below right=0.6cm and 0.63cm of q1] (q4) {$C$\\ \scriptsize{8}};
        \node[state,align=center] [right of=q3] (q5) {$A$\\ \scriptsize{3}};
        \node[state,align=center] [above right of=q5] (q6) {$T$\\ \scriptsize{4}};
        \node[state,align=center] [below right of=q5] (q7) {$G$\\ \scriptsize{7}};
        \node[state,align=center] [below right of=q6] (q8) {$A$\\ \scriptsize{5}};
        \node[state,align=center] [right of=q8] (q9) {$e$\\ \scriptsize{-1}};

        \path
        (q0) edge node {} (q1)
        (q1) edge node {} (q2)
        edge node {} (q3)
        edge node {} (q4)
        (q2) edge node {} (q5)
        (q3) edge node {} (q5)
        (q4) edge node {} (q5)
        (q5) edge node {} (q6)
        edge node {} (q7)
        edge node {} (q8)
        (q6) edge node {} (q8)
        (q7) edge node {} (q8)
        (q8) edge node {} (q9);
      \end{tikzpicture}
    \end{center}
  \end{mdframed}
  \caption{A graph made from the three sequences ``ATATA'', ``AGAGA'' and ``ACAA'' with 9 valid complete paths}
\end{figure}
\section{Overview}
``Fuzzy context-based search'' is an algorithm which solves the bounded optimal alignment score problem. The first step of the process is to build a searchable index based on the given graph $G$. This index is independent from the input sequences to be aligned, and can thus be used for several searches. The alignment itself consists of two steps: Building a new graph $G'$, from both $G$ and an input string $s$, and search for an alignment in this newly formed graph. Searching for an alignment means combining nodes, representing bases, into a path which represents a linear sequence. This linear sequence can be aligned against the input sequence with regular string alignment tools and is therefore easily scorable. If the algorithm finds an alignment this is guaranteed to be one of the paths which produces the highest possible alignment score for any path in the graph (See supplementary XXX \textcolor{red}{PROOF}). There are some situations where the algorithm results in an empty alignment. These cases will occur when there are no paths in the graph which produces an alignment score higher than the threshold $T$, and the sequence $s$ is identified as unmappable. When an empty alignment is provided as a basis for merging a new sequence into the graph, this results in a new complete path which is separated from the original vertices (See fig. \ref{fig:separate_paths})
\subsection{Precomputation of the graph}
There are two data structures needed for aligning any string against the graph, a suffix tree for left contexts and a suffix tree for right contexts. Before either of the two are built the algorithm needs to decide a length for the contexts. Currently in the tool there are two ways of setting the context length: A user given parameter or an approximation based on the probability of sharing contexts \textcolor{red}{SUPPLEMENTARY?}. The length of a context does not impact the quality of the alignments found by the algorithm \textcolor{red}{PROOF IN SUPPLEMENTARY?} but will have an impact on the runtime.\\
\par\noindent
\begin{wrapfigure}{r}{0.4\textwidth}
  \begin{subfigure}[t]{\textwidth}
    \begin{center}
      \begin{tabular}{c|c|c|c|c|}
          & T & C & A & G \\ \hline
        T & 0 & -1 & -2 & -3 \\ \hline
        C & -1 & 0 & -1 & -2 \\ \hline
        C & -2 & -1 & -1 & -2 \\ \hline
        G & -3 & -2 & -2 & -1 \\ \hline
      \end{tabular}
    \end{center}
    \caption{The dynamic programming table for aligning the two strings ``TCAG'' and ``TCCG'' using modified edit distance as a scoring schema}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \begin{center}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.1cm,scale=0.5]
        \node[state] (q0) {$s$};
        \node[state] [above right of=q0] (q1) {$T$};
        \node[state] [right of=q1] (q2) {$C$};
        \node[state] [right of=q2] (q3) {$A$};
        \node[state] [right of=q3] (q4) {$G$};
        \node[state] [below right of=q0] (q5) {$T$};
        \node[state] [right of=q5] (q6) {$C$};
        \node[state] [right of=q6] (q7) {$C$};
        \node[state] [right of=q7] (q8) {$G$};
        \node[state] [above right of=q8] (q9) {$e$};

        \path
        (q0) edge node {} (q1)
        edge node {} (q5)
        (q1) edge node {} (q2)
        (q2) edge node {} (q3)
        (q3) edge node {} (q4)
        (q4) edge node {} (q9)
        (q5) edge node {} (q6)
        (q6) edge node {} (q7)
        (q7) edge node {} (q8)
        (q8) edge node {} (q9);
      \end{tikzpicture}
    \end{center}
    \caption{The result of aligning and merging the sequences with $T=0$}
  \end{subfigure}
  \begin{subfigure}[t]{\textwidth}
    \begin{center}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.1cm,scale=0.6]
        \node[state] (q0) {$s$};
        \node[state] [right of=q0] (q1) {$T$};
        \node[state] [right of=q1] (q2) {$C$};
        \node[state] [above right of=q2] (q3) {$A$};
        \node[state] [below right of=q2] (q4) {$C$};
        \node[state] [below right of=q3] (q5) {$G$};
        \node[state] [right of=q5] (q6) {$e$};

        \path
        (q0) edge node {} (q1)
        (q1) edge node {} (q2)
        (q2) edge node {} (q3)
        edge node {} (q4)
        (q3) edge node {} (q5)
        (q4) edge node {} (q5)
        (q5) edge node {} (q6);
      \end{tikzpicture}
    \end{center}
    \caption{The result of aligning and merging the sequences with $T=1$}
  \end{subfigure}
  \label{fig:separate_paths}
\end{wrapfigure}
When a context length $|c|$ is set, the algorithm can start building the index. Two sets of strings, a left context set and a right context set, is generated for every node in the graph $G$. The generation of the two sets happen by the same procedure, by swapping around the starting point and the direction of the iteration. When creating left contexts the algorithm starts in the start-node of $G$ and traverses following the direction of the edges, for right contexts the opposite is done. Apart from this the two are equal. To generate the context set $c(n_x)$ for a given node $n_x$ the algorithm looks at every string $c \in c(n_y)$ for every incoming neighbouring node $n_y$. Every $c$ is modified into a new context string $c'$ by trimming away the last character and prefixing the context with \textcolor{red}{the character $b$ stored in $n_y$}. All the generated strings $c'$ is added to $c(n_x)$. As sets per definition does not allow duplicates the impact of a branching occuring in the graph will fade away after exactly $|c|$ steps as the difference is trimmed away (see Fig. \ref{fig:explicit_contexts}), and thus avoid explosive exponentiality in the context set sizes.\\
\par\noindent
The iteration starts in the node defined as the starting point which has the empty string $\epsilon$ as its only context. Whenever a node has finished producing its contexts it enqueues everyone of its outgoing neighbours in a regular FIFO queue. If a node has more actual incoming neighbours than incoming neighbours which are finished generating contexts, the node puts itself back in the queue. The algorithm halts when the queue is empty. Every node has to be visited exactly once to generate its context and as the procedure runs twice to generate both sets the total runtime for the operation is $O(2|G|)$.\\
\begin{figure}[b!]
	\begin{center}
		\begin{mdframed}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
				\node[state,align=center,minimum size=3cm,scale=0.75] (q0) {\footnotesize{\{"$G$", "$T$"\}}\\\Large{\textbf{$A$}}\\\footnotesize{\{"$TA$"\}}\\\scriptsize{$2$}};
				\node[state,align=center,minimum size=3cm,scale=0.75] [below left of=q0] (q1) {\footnotesize{$\{\epsilon\}$}\\$G$\\\footnotesize{\{"$AT$"\}}\\\scriptsize{$6$}};
				\node[state,align=center,minimum size=3cm,scale=0.75] [above left of=q0] (q2) {\footnotesize{$\{\epsilon\}$}\\$T$\\\footnotesize{\{"$AT$"\}}\\\scriptsize{$1$}};
				\node[state,align=center,minimum size=3cm,scale=0.75] [right of=q0] (q3) {\\\footnotesize{\{"$AG$", "$AT$"\}}\\$T$\\\footnotesize{\{"$AG$"\}}\\\scriptsize{$3$}};
				\node[state,align=center,minimum size=3cm,scale=0.75] [right of=q3] (q4) {\footnotesize{\{"$TA$"\}}\\$A$\\\footnotesize{\{"$G$"\}}\\\scriptsize{$4$}};
				\node[state,align=center,minimum size=3cm,scale=0.75] [right of=q4] (q5) {\footnotesize{\{"$AT$"\}}\\$G$\\\footnotesize{$\{\epsilon\}$}\\\scriptsize{$5$}};

				\path
				(q1) edge node {} (q0)
				(q2) edge node {} (q0)
				(q0) edge node {} (q3)
				(q3) edge node {} (q4)
				(q4) edge node {} (q5);

			\end{tikzpicture}
		\end{mdframed}
	\end{center}
	\caption{A small reference graph with left contexts (top) and right contexts (bottom) of length 2 shown}
	\label{fig:explicit_contexts}
\end{figure}
\par\noindent
\begin{wrapfigure}{l}{0.49\textwidth}
	\begin{mdframed}
		\begin{tikzpicture}
			\node[state,align=center,minimum size=1.4cm] (q0) {$\epsilon$\\\scriptsize{\{$1,6$\}}};
			\node[state,align=center,minimum size=1.4cm] [below left=0.6cm and 0.6cm of q0] (q1) {$A$\\\scriptsize{$\emptyset$}};
			\node[state,align=center,minimum size=1.4cm] [below=0.21cm of q0] (q2) {$G$\\\scriptsize{\{$2$\}}};
			\node[state,align=center,minimum size=1.4cm] [below right=0.6cm and 0.6cm of q0] (q3) {$T$\\\scriptsize{\{$2$\}}};
			\node[state,align=center,minimum size=1.4cm] [below left=0.6cm and 0cm of q1] (q4) {$G$\\\scriptsize{\{$3$\}}};
			\node[state,align=center,minimum size=1.4cm] [below right=0.6cm and 0cm of q1] (q5) {$T$\\\scriptsize{\{$3,5$\}}};
			\node[state,align=center,minimum size=1.4cm] [below=0.2cm of q3] (q6) {$A$\\\scriptsize{\{$4$\}}};

			\path
			(q0) edge node {} (q1)
			edge node {} (q2)
			edge node {} (q3)
			(q1) edge node {} (q4)
			edge node {} (q5)
			(q3) edge node {} (q6);
		\end{tikzpicture}
	\end{mdframed}
	\caption{The left suffix tree corresponding to the graph in \ref{fig:explicit_contexts}}
	\label{fig:left_suffix_tree}
\end{wrapfigure}
After generating the two context sets for every node, the elements of each one is inserted into their corresponding suffix tree. In theory every node can have $4^{|c|}$ contexts in each set. When the graph is more or less linear with few branches a more fair approximation is $B*|c|$ where $B$ is the observed branching factor. The current implementation in the tool uses a naive suffix tree where insertion is $O(|c|)$. This is done for every node in the graph, yielding a total time complexity of $O(|G|B|c|^2)$. A discussion on more efficient suffix structures can be found in \textcolor{red}{SOMEWHERE IN DISCUSSION}. Every suffix is stored as a key with the index of it's originating node as a value. The total runtime for building a searchable index for a graph is $O(3|G||c|^2B)$
\section{Generating the new graph G'}
Creating $G'$ is the process of determining which nodes qualifies as candidate nodes for a given input string $s$ and combining them correctly. In order to determine actual candidates for the given string, the algorithm needs to know how much \textit{fuzzyness} to allow. This is a measure which decides how different a read can be from its optimal counterpart in the graph before it is categorized as not mappable. The algorithm takes in a fuzzyness parameter $\lambda$ and decides this by setting a threshold $T=maxScore(s)-\lambda$. The maximal score is found by mapping the string, be it the entire input string or a context string, against itself with a scoring function provided by the scoring schema. Both $\lambda$ and $T$ is used throughout the entire process as cutoff variables.\\
\par\noindent
For every character $s_x \in s$ a left-context string and a right-context string is generated by looking at the $|c| + maxPossibleGapGivenThreshold(T)$ surrounding characters. The two strings are treated as contexts, one left and one right, and used as a basis for a fuzzy search in it's corresponding suffix tree. The search is a recursive function based on PO-MSA. The root node is supplied with a one-dimensional scoring array corresponding to the context string $c$, which is initialized with all zeroes. Then, for every child, a new scoring array is computed by regular edit distance rules: For each index $i$ take the maximal score for either a gap in the graph, a gap in the string or matching the character $c_i$ with the character contained in the child node \textcolor{red}{(Reference actual code in supplementary?), (more explanation needed?)}. This newly created array is supplemented to the same recursive function in the child. When a leaf node is reached the last index of the supplied scoring array corresponds to mapping the entire string $c$ against the entire context achieved by concatenating the characters contained in the path traversed by the recursion. If the score is higher than the threshold $T$ every index contained in the node is stored as a pair on the form $\{index, score\}$ to the candidate set. If an index is stored several times, only the pair containing the highest score is saved.\\
\par\noindent
\par
\begin{wrapfigure}{r}{0.5\textwidth} 
	\begin{subfigure}[t]{\textwidth}
		\begin{mdframed}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
				\node[state,draw=none,align=center] (q0) {$A$\\\scriptsize{LC=$\epsilon$}\\\scriptsize{RC="$TA$"}};
				\node[state,draw=none,align=center] [right=-0.15cm of q0] (q1) {$T$\\\scriptsize{LC="$A$""}\\\scriptsize{RC="$A$"}};
				\node[state,draw=none,align=center] [right=-0.15cm of q1] (q2) {$A$\\\scriptsize{LC="$TA$""}\\\scriptsize{RC=$\epsilon$}};

				\node[state,align=center] [below=0cm of q0] (q3) {$A$\\\scriptsize{$2$}};
				\node[state,align=center] [below=0cm of q1] (q4) {$T$\\\scriptsize{$3$}};
				\node[state,align=center] [below=0cm of q2] (q5) {$A$\\\scriptsize{$4$}};
			\end{tikzpicture}
		\end{mdframed}
		\caption{$T=0$}
	\end{subfigure}	
	\begin{subfigure}[t]{\textwidth}
		\begin{mdframed}
			\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,scale=0.6]
				\node[state,draw=none,align=center] (q0) {$A$\\\scriptsize{LC=$\epsilon$}\\\scriptsize{RC="$TA$"}};
				\node[state,draw=none,align=center] [right=-0.15cm of q0] (q1) {$T$\\\scriptsize{LC="$A$""}\\\scriptsize{RC="$A$"}};
				\node[state,draw=none,align=center] [right=-0.15cm of q1] (q2) {$A$\\\scriptsize{LC="$TA$""}\\\scriptsize{RC=$\epsilon$}};

				\node[state,align=center] [below=0cm of q0] (q3) {$T$\\\scriptsize{$1$}};
				\node[state,align=center] [below=0.3cm of q3] (q4) {$A$\\\scriptsize{$2$}};
				\node[state,align=center] [below=0.3cm of q4] (q5) {$T$\\\scriptsize{$3$}};
				\node[state,align=center] [below=0.3cm of q5] (q6) {$G$\\\scriptsize{$6$}};

				\node[state,align=center] [below=0cm of q1] (q7) {$T$\\\scriptsize{$1$}};
				\node[state,align=center] [below=0.3cm of q7] (q9) {$T$\\\scriptsize{$3$}};
				\node[state,align=center] [below=0.3cm of q9] (q11) {$G$\\\scriptsize{$5$}};
				\node[state,align=center] [below=0.3cm of q11] (q12) {$G$\\\scriptsize{$6$}};

				\node[state,align=center] [below=0cm of q2] (q13) {$T$\\\scriptsize{$3$}};
				\node[state,align=center] [below=0.3cm of q13] (q14) {$A$\\\scriptsize{$4$}};
				\node[state,align=center] [below=0.3cm of q14] (q15) {$G$\\\scriptsize{$5$}};
			\end{tikzpicture}
		\end{mdframed}
		\caption{$T=1$}
	\end{subfigure}
	\caption{The resulting candidate sets for mapping the string "ATA" against the reference genome from ~\ref{fig:explicit_contexts} with varying T values}
	\label{fig:candidate_nodes}
\end{wrapfigure}
After the fuzzy search is concluded there are two sets of candidates for every index, one containing the nodes matching the left context and an equivalent for nodes matching the right context. These two sets are intersected to produce a final candidate set for the index $i$, where the score is created by adding together the scores from the two original. When the intersection happens the final set can again be pruned by removing all vertices which has a combined score that is lower than the sum of the maximal score for each context minus $\lambda$. When the vertices are found the edges need to be generated in order to finish the graph. Intuitively there should be an edge whereever there is a gap which is traversable without having the gap penalty exceeding $\lambda$. In practice this is a step which is done during the next step of the algorithm.\\
\clearpage
The newly formed graph $G'$ can be defined formally:\\
$G'(G, s, T) = \{V', E'\}$ 
where $V'$ is an ordered set of sets of length $|s|$ where each set $V'_i$ is a set of nodes such that\\
\par
$V'_i=\{v_x|v_x \in G \wedge contextScore(v_x, s_i) >= T\}$\\
\par\noindent
and $E'$ is a list of weighted edges such that\\
\par
$E'=\{e'=\{i_s, i_e, w\}|i_s \in V'_x \wedge i_e \wedge V'_y \wedge$ $gapPenalty(y - x) <= \lambda$\par$ \wedge w=distance(i_s, i_e) \wedge gapPenalty(w) <= \lambda\}$\\
\par\noindent
where $contextScore(x, y)$ and $gapPenalty(x, y)$ are scoring functions provided by the scoring schema and $distance(x, y)$ is the distance of the shortest path from node $x$ to node $y$ in the graph. \textcolor{red}{(Mixing up nodes and indexes in the definitions)}\\
\par\noindent
In theory every leaf node has to be visited in order to check the score for every represented context in the tree. In practice the tree can be pruned by cutting off the search whenever the \textit{maximal potential score}\textcolor{red}{(clumsy name)} falls below the threshold. The maximal potential score for a node is found by adding together the currently highest score in the scoring array with the maximal matching score for the remainder of the string. This reduces the number of nodes to be searched from $O(4^c)$ to \textcolor{red}{(something alot smaller. Needs calculations)}.\\
\section{Searching G' with the modified PO-MSA}
When the candidate nodes for each position has been chosen there remains one final step: How to combine them in the best possible way to produce an actual path. This corresponds with finding the path through $G'$ which traversal gives an optimal score within the scoring schema. Conceptually this is in many ways similar to a regular PO-MSA search where instead of searching through the reference graph with an input string we are searching through a graph of the string with the graph as our input. Instead of giving every node a score for every index in the string we give every index of the string a score for every candidate node. This presents one problem: We need to decide the gap score for jumping between arbitrary nodes in our graph. In the regular case with strings this is easily done by taking the differences in the indexes of two elements, whereas for graphs we need to find the distance between nodes through searching for shortest paths. We do however know we are not interested in alignments which does not have a score within our given threshold, which means we can bound the search to every node which is reachable without letting the gap penalty fall below $\lambda$.\\
\par\noindent
\begin{wrapfigure}{l}{0.5\textwidth}
  \begin{subfigure}[t]{0.49\textwidth}
    \begin{center}
      \begin{tabular}{|c|c|c|}
        A & T & A \\ \hline 
        1 & 1 & 3 \\ \hline
        2 & 2 & 4 \\ \hline
        3 & 3 & 5 \\ \hline
        6 & 4 & X \\ \hline
        X & 5 & X \\ \hline
        X & 6 & X \\ \hline
      \end{tabular}
    \end{center}
    \caption{Indexes}
  \end{subfigure}
  \begin{subfigure}[t]{0.49\textwidth}
    \begin{center}
      \begin{tabular}{|c|c|c|}
        A & T & A \\ \hline 
       -1 & -2 & -2 \\ \hline
        0 & -2 & 0 \\ \hline
        -1 & 0 & -2 \\ \hline
        -1 & -2 & X \\ \hline
        X & -3 & X \\ \hline
        X & -3 & X \\ \hline
      \end{tabular}
    \end{center}
    \caption{Scores}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \begin{center}
      \begin{tabular}{|c|c|c|}
        A & T & A \\ \hline 
        F & F & F \\ \hline
        F & F & F \\ \hline
        F & F & T \\ \hline
        F & T & X \\ \hline
        X & T & X \\ \hline
        X & F & X \\ \hline
      \end{tabular}
    \end{center}
    \caption{Gaps}
  \end{subfigure}
  \begin{subfigure}[b]{0.49\textwidth}
    \begin{center}
      \begin{tabular}{|c|c|c|}
        A & T & A \\ \hline 
        -1:-1 & 0:1 & 1:2 \\ \hline
        -1:-1 & 0:1 & 1:2 \\ \hline
        -1:-1 & 0:2 & 1:2 \\ \hline
        -1:-1 & 0:2 & X \\ \hline
        X & 0:3 & X \\ \hline
        X & 0:4 & X \\ \hline
      \end{tabular}
    \end{center}
    \caption{Backpointers}
  \end{subfigure}
  \caption{The 4 arrays used by the searching algorithm when using the candidate sets from Fig \ref{fig:canditate_nodes} and $T=1$}
  \label{fig:scoring_arrays}
\end{wrapfigure}
The implemented search solves the problem through dynamic programming. For every index $i$ look at every node $n_x$ in the candidate set. For each of these nodes make pairs with every node $n_y$ of every candidate set for the preceding indexes $j$. Once again we know gaps with a penalty larger then $\lambda$ is not interesting and can bound the distance of the search backwards. For each of these pairs make a score by combining the score in the previous node with the mapping score for the character $b$ stored in $n_x$ mapped against $s_i$ aswell as the gap penalty for traversing from index $j$ to $i$ and for traversing the graph from $n_x$ to $n_y$. For all scoring schemas where the penalty for a gap is larger than or equal to the worst possible mapping score between bases, the two preceding cases will never happen at the same time. The final score for a node is the maximal attainable score found through searching these pairs. In order to store the scores we need an array of integer arrays the same size as the array of arrays of candidate nodes. To handle non-linear gap penalties we need a boolean array the same size to store gap-information. Lastly, in order to backtrack to find the path yielding the highest score we need a backpointer array consisting of pairs of integers. The resulting space complexity is $O(5\textcolor{red}{SIZE OF CANDIDATE SETS})$. The average case time complexity of the search is $O(\dfrac{|s|T^4c^2|G|^2}{4^{|c|^2}})$ \textcolor{red}{Reference supplementary}.
\section{Handling invalid threshold values}
\section{Merging}
\end{document}