\documentclass[thesis.tex]{subfiles}

\begin{document}
\chapter{Implementation}
In this section we will present the implementation of the algorithm ``Fuzzy context-based search'' which is found in the \textit{GraphGenome} tool (Appendix \ref{sec:tool}). The algorithm will be coupled by a concrete example which is found in figures \ref{fig:explicit_contexts}-\ref{fig:candidate_nodes} and table \ref{fig:scoring_arrays}. Throughout this chapter, and in the example, the scoring schema is assumed to be the \textit{negated edit distance} schema. This scoring schema is chosen due to its intuitive nature: A final score of $-x$ means there is something wrong in exactly $x$ places. The scoring schema is also practical for doing complexity analysis: A gap which is penalized by $y$ means traversing exactly $y$ vertices or indexes.
\begin{defn}[Negated edit distance scoring schema]
  A scoring schema where the substitution matrix is a variant of an identity matrix where matches are scored 0 and mismatches are scored -1. Both the gap opening and gap extension penalty is -1
\end{defn}
The chapter is divided into two sections. The first explains the implementation of the algorithm corresponding to the previous chapter. The second is a brief overview of how the tool merges sequences into the graph after they have been aligned. This section is included to better provide an intuition as to how the graphs are built and what readers can expect when seeing the results and using the tool themselves.
\section{Aligning sequences}
The alignment process consists of the two steps described in the previous chapter which each has their corresponding subsection. In addition to this the tool needs to do a precomputation of the original graph in order to build a searchable index. This is not counted as a step in the alignment process as theprecomputation is determined by only the graph and the index is thus reusable.
\subsection{Building the index}
There are two data structures needed for aligning a string against the graph: a suffix tree for left contexts and a suffix tree for right contexts. Before either of the two are built the algorithm needs to decide a length for the contexts. Currently in the tool there are two ways of setting the context length: A user given parameter or an approximation based on the probability of sharing contexts (Appendix \ref{sec:birthday_problem}). The length of the contexts does not impact the quality of the alignments found by the algorithm (Appendix \ref{sec:proof}) but will have an impact on the runtime (Appendix \ref{sec:complexity_analysis}).\\
\par\noindent
\begin{wrapfigure}{r}{0.5\textwidth}
  \begin{mdframed}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tabularx}{\linewidth}{ccccc}
            & T & C & A & G \\ \cline{2-5}
            T & \multicolumn{1}{|c|}{0} & -1 & \multicolumn{1}{|c|}{-2} & \multicolumn{1}{c|}{-3} \\ \cline{2-5}
            C & \multicolumn{1}{|c|}{-1} & 0 & \multicolumn{1}{|c|}{-1} & \multicolumn{1}{c|}{-2} \\ \cline{2-5}
            C & \multicolumn{1}{|c|}{-2} & -1 & \multicolumn{1}{|c|}{-1} & \multicolumn{1}{c|}{-2} \\ \cline{2-5}
            G & \multicolumn{1}{|c|}{-3} & -2 & \multicolumn{1}{|c|}{-2} & \multicolumn{1}{c|}{-1} \\ \cline{2-5}
          \end{tabularx}
        \end{center}
      \end{mdframed}
      \caption{The dynamic programming table for aligning the two strings ``TCAG'' and ``TCCG'' using negated edit distance as a scoring schema}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.3cm]
            \node[state,scale=0.7] (q0) {$s$};
            \node[state,scale=0.7] [above right of=q0] (q1) {$T$};
            \node[state,scale=0.7] [right of=q1] (q2) {$C$};
            \node[state,scale=0.7] [right of=q2] (q3) {$A$};
            \node[state,scale=0.7] [right of=q3] (q4) {$G$};
            \node[state,scale=0.7] [below right of=q0] (q5) {$T$};
            \node[state,scale=0.7] [right of=q5] (q6) {$C$};
            \node[state,scale=0.7] [right of=q6] (q7) {$C$};
            \node[state,scale=0.7] [right of=q7] (q8) {$G$};
            \node[state,scale=0.7] [above right of=q8] (q9) {$e$};

            \path
            (q0) edge node {} (q1)
            edge node {} (q5)
            (q1) edge node {} (q2)
            (q2) edge node {} (q3)
            (q3) edge node {} (q4)
            (q4) edge node {} (q9)
            (q5) edge node {} (q6)
            (q6) edge node {} (q7)
            (q7) edge node {} (q8)
            (q8) edge node {} (q9);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{The result of aligning and merging the sequences with $T=0$}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.3cm]
            \node[state,scale=0.7] (q0) {$s$};
            \node[state,scale=0.7] [right of=q0] (q1) {$T$};
            \node[state,scale=0.7] [right of=q1] (q2) {$C$};
            \node[state,scale=0.7] [above right of=q2] (q3) {$A$};
            \node[state,scale=0.7] [below right of=q2] (q4) {$C$};
            \node[state,scale=0.7] [below right of=q3] (q5) {$G$};
            \node[state,scale=0.7] [right of=q5] (q6) {$e$};

            \path
            (q0) edge node {} (q1)
            (q1) edge node {} (q2)
            (q2) edge node {} (q3)
            edge node {} (q4)
            (q3) edge node {} (q5)
            (q4) edge node {} (q5)
            (q5) edge node {} (q6);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{The result of aligning and merging the sequences with $T=-1$}
    \end{subfigure}
  \end{mdframed}
  \caption{Different scoring thresholds $T$ yields different reference graphs}
  \label{fig:separate_paths}
\end{wrapfigure}
When a context length $|c|$ is set, the algorithm can start building the index. Two sets of strings, a left context set and a right context set, is generated for every vertice in the graph $G$. The generation of the two sets happen by the same procedure by swapping around the starting point and the direction of the iteration. When creating left contexts the algorithm starts in the start-node of $G$ and traverses following the direction of the edges, for right contexts the opposite is done. Apart from this the two are equal. To generate the context set $c(n_x)$ for a given node $n_x$ the algorithm looks at every string $c \in c(n_y)$ for every incoming neighbouring node $n_y$. Every $c$ is modified into a new context string $c'$ by trimming away the last character and prefixing the context with the character $b(n_y)$. All the generated strings $c'$ is added to $c(n_x)$. As sets per definition does not allow duplicates the impact of a branching occuring in the graph will fade away after exactly $|c|$ steps as the difference is trimmed away (see Fig. \ref{fig:explicit_contexts}), and thus avoid explosive exponentiality in the context set sizes. Unlike Paten et al. \cite{mapping_to_a_reference_genome_structure} there are no requirements for contexts to be uniquely mappable to exactly one vertice. Because the last step of the algorithm does a search for an incomplete path through all the candidate vertices this presents no difficulties when finding the alignment. Furthermore, dropping this precondition assures every node has two valid contexts and are thus present in both suffix trees.\\
\par\noindent
The iteration starts in the node defined as the starting point which has the empty string $\epsilon$ as its only context. Whenever a node has finished producing its contexts it enqueues everyone of its outgoing neighbours in a regular FIFO queue. If a vertice has more actual incoming neighbours than incoming neighbours which are finished generating contexts, the node puts itself back in the queue. Thus happens to ensure that when a vertice is finished generating context, both the vertice itself and all preceding vertices are finished, and the remaining nodes can safely fetch contexts from its neighbours knowing they are finished. The algorithm halts when the queue is empty. Every node has to be visited exactly once to generate its context, looking up its approximately $b$ neighbours, and as the procedure runs twice to generate both sets the total runtime for the operation is $O(2|G|b)$.\\
\begin{figure}[t!]
  \begin{center}
    \begin{mdframed}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
        \node[state,align=center,minimum size=3cm,scale=0.75] (q0) {\footnotesize{\{"$G$", "$T$"\}}\\\Large{\textbf{$A$}}\\\footnotesize{\{"$TA$"\}}\\\scriptsize{$2$}};
        \node[state,align=center,minimum size=3cm,scale=0.75] [below left of=q0] (q1) {\footnotesize{$\{\epsilon\}$}\\$G$\\\footnotesize{\{"$AT$"\}}\\\scriptsize{$6$}};
        \node[state,align=center,minimum size=3cm,scale=0.75] [above left of=q0] (q2) {\footnotesize{$\{\epsilon\}$}\\$T$\\\footnotesize{\{"$AT$"\}}\\\scriptsize{$1$}};
        \node[state,align=center,minimum size=3cm,scale=0.75] [right of=q0] (q3) {\\\footnotesize{\{"$AG$", "$AT$"\}}\\$T$\\\footnotesize{\{"$AG$"\}}\\\scriptsize{$3$}};
        \node[state,align=center,minimum size=3cm,scale=0.75] [right of=q3] (q4) {\footnotesize{\{"$TA$"\}}\\$A$\\\footnotesize{\{"$G$"\}}\\\scriptsize{$4$}};
        \node[state,align=center,minimum size=3cm,scale=0.75] [right of=q4] (q5) {\footnotesize{\{"$AT$"\}}\\$G$\\\footnotesize{$\{\epsilon\}$}\\\scriptsize{$5$}};

        \path
        (q1) edge node {} (q0)
        (q2) edge node {} (q0)
        (q0) edge node {} (q3)
        (q3) edge node {} (q4)
        (q4) edge node {} (q5);

      \end{tikzpicture}
    \end{mdframed}
  \end{center}
  \caption{A small reference graph with left contexts (top) and right contexts (bottom) of length 2 shown}
  \label{fig:explicit_contexts}
\end{figure}
\par\noindent
After generating the two context sets for every node, the elements of each one is inserted into their corresponding suffix tree. Every suffix is stored as a key with the index of it's originating node as a value (fig. \ref{fig:left_suffix_tree}). In theory every node can have $4^{|c|}$ contexts in each set, in practice a more fair approximation is $b^{|c|}$ where $b$ is the observed branching factor for the graph. \textcolor{red}{Should contain something about probable values of B. Find an article on it}. 
\begin{wrapfigure}{R}{0.49\textwidth}
  \begin{mdframed}
    \begin{tikzpicture}
      \node[state,align=center,minimum size=1.4cm] (q0) {$\epsilon$\\\scriptsize{\{$1,6$\}}};
      \node[state,align=center,minimum size=1.4cm] [below left=0.6cm and 0.6cm of q0] (q1) {$A$\\\scriptsize{$\emptyset$}};
      \node[state,align=center,minimum size=1.4cm] [below=0.21cm of q0] (q2) {$G$\\\scriptsize{\{$2$\}}};
      \node[state,align=center,minimum size=1.4cm] [below right=0.6cm and 0.6cm of q0] (q3) {$T$\\\scriptsize{\{$2$\}}};
      \node[state,align=center,minimum size=1.4cm] [below left=0.6cm and 0cm of q1] (q4) {$G$\\\scriptsize{\{$3$\}}};
      \node[state,align=center,minimum size=1.4cm] [below right=0.6cm and 0cm of q1] (q5) {$T$\\\scriptsize{\{$3,5$\}}};
      \node[state,align=center,minimum size=1.4cm] [below=0.2cm of q3] (q6) {$A$\\\scriptsize{\{$4$\}}};

      \path
      (q0) edge node {} (q1)
      edge node {} (q2)
      edge node {} (q3)
      (q1) edge node {} (q4)
      edge node {} (q5)
      (q3) edge node {} (q6);
    \end{tikzpicture}
  \end{mdframed}
  \caption{The left suffix tree corresponding to the graph in \ref{fig:explicit_contexts}}
  \label{fig:left_suffix_tree}
\end{wrapfigure}
The current implementation uses a naive suffix tree implementation where insertion is $O(|c|)$, giving a total time complexity of $O(b^{|c|}|c|)$ per node per context set and $O(2|G|b^{|c|}|c|)$ for the entire graph. Building the entire index can thus be done in $O(2|G|b + 2|G|b^{|c|}|c|)$.
\subsection{Generating the modified graph}
The produced graph $G'$ is a function of both the original graph $G$, the input sequence $s$ and the threshold $T$. For every character $s_x \in s$ a left-context string and a right-context string is generated by looking at the $|c| + maxPossibleGapGivenFuzzyness(\lambda)$ surrounding characters. The two context strings are used as a basis for a fuzzy search in it's corresponding suffix tree. The search is a recursive function based on PO-MSA. The root node is supplied with a one-dimensional scoring array corresponding to the context string $c$, which is initialized with all zeroes. Then, for every child, a new scoring array is computed by regular edit distance rules: For each index $i$ take the maximal score for either a gap in the graph, a gap in the string or matching the character $c_i$ with the character contained in the child node \textcolor{red}{(Reference actual code in supplementary?), (more explanation needed?)}. This newly created array is supplemented to the same recursive function in the child. When a leaf node is reached the last index of the supplied scoring array corresponds to mapping the entire string $c$ against the entire context achieved by concatenating the characters contained in the path through the tree traversed by the recursion. If the score is higher than the context threshold $T_c$ for the given context string, every index contained in the node is stored as a pair on the form $\{index, score\}$ in the candidate set. If an index is stored several times, only the pair containing the highest score is saved.\\
\par\noindent
In order to also be able to look up contexts which are shorter than the contexts stored in the tree, the suffix tree search implementation has built in a concept which we called \textcolor{red}{something smart}. This concepts allow all vertices at a depth greater than the length of the string which is looked up to pass on their highest possible score, and avoids deteroriation of context scores due to different length and are typically used for the shorter contexts at the beginning and end of reads.\\
\par\noindent
Additionally the suffix search does one more optimization. Whenever the context is short, defined as \textit{shorter than $|c|$}, there will be alot of matches, and the tool has to iterate over every single one to subtract its indexes. In these cases the tool simply handles returns an empty set which is treated as a set containing every single index with a maximal score. But even this seemingly simple operation has pitfalls to avoid. Whenever the provided string has a length $|l| < 2*c+1$ the middle elements will have contexts on either side which is not searched due to their length, which provides two empty sets. To avoid this the suffix tree search has built in a \textit{force} option, which assures atleast one set of candidate vertices is always found.\\
\par\noindent
In theory every leaf node has to be visited in order to check the score for every represented context in the tree. In practice the tree can be pruned by cutting off the search whenever the \textit{maximal potential score} falls below the threshold $T_c$ for the provided context. The maximal potential score for a node is found by adding together the currently highest score in the scoring array with the maximal matching score for the remainder of the string. This reduces the number of nodes to be searched from $O(4^c)$ to \textcolor{red}{(something alot smaller. Needs calculations)}.\\
\clearpage
\begin{wrapfigure}{L}{0.5\textwidth} 
  \begin{subfigure}[t]{\textwidth}
    \begin{mdframed}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm]
        \node[state,draw=none,align=center] (q0) {$A$\\\scriptsize{LC=$\epsilon$}\\\scriptsize{RC="$TA$"}};
        \node[state,draw=none,align=center] [right=-0.15cm of q0] (q1) {$T$\\\scriptsize{LC="$A$""}\\\scriptsize{RC="$A$"}};
        \node[state,draw=none,align=center] [right=-0.15cm of q1] (q2) {$A$\\\scriptsize{LC="$TA$""}\\\scriptsize{RC=$\epsilon$}};

        \node[state,align=center] [below=0cm of q0] (q3) {$A$\\\scriptsize{$2$}};
        \node[state,align=center] [below=0cm of q1] (q4) {$T$\\\scriptsize{$3$}};
        \node[state,align=center] [below=0cm of q2] (q5) {$A$\\\scriptsize{$4$}};
      \end{tikzpicture}
    \end{mdframed}
    \caption{$T=0$}
  \end{subfigure}	
  \begin{subfigure}[t]{\textwidth}
    \begin{mdframed}
      \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3.5cm,scale=0.6]
        \node[state,draw=none,align=center] (q0) {$A$\\\scriptsize{LC=$\epsilon$}\\\scriptsize{RC="$TA$"}};
        \node[state,draw=none,align=center] [right=-0.15cm of q0] (q1) {$T$\\\scriptsize{LC="$A$""}\\\scriptsize{RC="$A$"}};
        \node[state,draw=none,align=center] [right=-0.15cm of q1] (q2) {$A$\\\scriptsize{LC="$TA$""}\\\scriptsize{RC=$\epsilon$}};

        \node[state,align=center] [below=-0.04cm of q0] (q3) {$T$\\\scriptsize{$1$}};
        \node[state,align=center] [below=0.3cm of q3] (q4) {$A$\\\scriptsize{$2$}};
        \node[state,align=center] [below=0.3cm of q4] (q5) {$T$\\\scriptsize{$3$}};
        \node[state,align=center] [below=0.3cm of q5] (q6) {$G$\\\scriptsize{$6$}};

        \node[state,align=center] [below=0cm of q1] (q7) {$T$\\\scriptsize{$1$}};
        \node[state,align=center] [below=0.3cm of q7] (q9) {$T$\\\scriptsize{$3$}};
        \node[state,align=center] [below=0.3cm of q9] (q11) {$G$\\\scriptsize{$5$}};
        \node[state,align=center] [below=0.3cm of q11] (q12) {$G$\\\scriptsize{$6$}};

        \node[state,align=center] [below=-0.07cm of q2] (q13) {$T$\\\scriptsize{$3$}};
        \node[state,align=center] [below=0.3cm of q13] (q14) {$A$\\\scriptsize{$4$}};
        \node[state,align=center] [below=0.3cm of q14] (q15) {$G$\\\scriptsize{$5$}};
      \end{tikzpicture}
    \end{mdframed}
    \caption{$T=1$}
  \end{subfigure}
  \caption{The resulting candidate sets for mapping the string "ATA" against the reference genome from fig. ~\ref{fig:explicit_contexts} with varying T values}
  \label{fig:candidate_nodes}
\end{wrapfigure}
After the fuzzy search is concluded there are two sets of candidates for every index, one containing the nodes matching the left context and an equivalent for nodes matching the right context. These two sets are intersected to produce a final candidate set for the index $i$, where the score is created by adding together the scores from the two original sets. When the intersection happens the final set can again be pruned by removing all vertices which has a combined score that is lower than the combined threshold $T$ for both contexts. Whenever one of the sets are empty, which represents every index matching, the intersection is emulated by simply taking the non-empty set. \\
\par\noindent
When the vertices are found the edges need to be generated in order to finish the graph. Intuitively there should be an edge whereever there is a gap which is traversable without having the gap penalty exceeding $\lambda$. Implementation-wise this is a step which is done during the next step of the algorithm.\\
\par\noindent
The newly formed graph $G'$ can be defined formally:\\
\par
$G'(G, s, T) = \{V', E'\}$\\
\par\noindent
where $V'$ is an ordered set of sets of length $|s|$ where each set $V'_i$ is a set of nodes such that\\
\par
$V'_i=\{v_x|v_x \in G \land \exists [c \in c(v_x)](alignmentScore(c, c(s_i)) >= T)\}$\\
\par\noindent
and $E'$ is a list of weighted edges such that\\
\par
$E'=\{e'=\{i_s, i_e, w\}|v_{i_s} \in V'_x \wedge v_{i_e} \in V'_y \wedge$ $gapPenalty(y - x) <= \lambda \wedge $\par$w=distance(v_{i_s}, v_{i_e}) \wedge gapPenalty(w) <= \lambda\}$\\
\par\noindent
where $alignmentScore(x, y)$ and $gapPenalty(x, y)$ are scoring functions provided by the scoring schema and $distance(x, y)$ is the distance of the shortest path from node $x$ to node $y$ in the graph. \textcolor{red}{(Mixing up nodes and indexes in the definitions)}\\
\par\noindent
\subsection{Searching G' with a modified PO-MSA search}
\textcolor{red}{SOMETHING ABOUT SCORES}\\
\par\noindent
\begin{wraptable}{l}{0.5\textwidth}
  \begin{mdframed}
    \begin{subfigure}[t]{0.49\textwidth}
      \begin{center}
        \begin{tabularx}{\textwidth}{ccc}
          A & T & A \\ \cline{1-3}
          \multicolumn{1}{|c|}{1} & 1 & \multicolumn{1}{|c|}{3} \\ \cline{1-3}
          \multicolumn{1}{|c|}{2} & 3 & \multicolumn{1}{|c|}{4} \\ \cline{1-3}
          \multicolumn{1}{|c|}{3} & 5 & \multicolumn{1}{|c|}{5} \\ \cline{1-3}
          \multicolumn{1}{|c|}{6} & 6 & \multicolumn{1}{|c}{ }  \\ \cline{1-2}
        \end{tabularx}
        \caption{Indexes}
      \end{center}
    \end{subfigure}
    \begin{subfigure}[t]{0.49\textwidth}
      \begin{center}
        \begin{tabularx}{\textwidth}{ccc}
          A & T & A \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1} & -2 & \multicolumn{1}{|c|}{-2} \\ \cline{1-3}
          \multicolumn{1}{|c|}{0} & 0 & \multicolumn{1}{|c|}{0} \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1} & -3 & \multicolumn{1}{|c|}{-2} \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1} & -3 & \multicolumn{1}{|c}{ }  \\ \cline{1-2}
        \end{tabularx}
        \caption{Scores}
      \end{center}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
      \begin{center}
        \begin{tabularx}{\textwidth}{ccc}
          A & T & A \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1:-1} & 0:0 & \multicolumn{1}{|c|}{1:1} \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1:-1} & 0:1 & \multicolumn{1}{|c|}{1:1} \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1:-1} & 0:2 & \multicolumn{1}{|c|}{1:1} \\ \cline{1-3}
          \multicolumn{1}{|c|}{-1:-1} & 0:3 & \multicolumn{1}{|c}{ }  \\ \cline{1-2}
        \end{tabularx}
        \caption{Backpointers}
      \end{center}
    \end{subfigure}
  \end{mdframed}
  \caption{The 4 arrays used by the searching algorithm when using the candidate sets from Fig \ref{fig:candidate_nodes} and $T=-1$}
  \label{fig:scoring_arrays}
\end{wraptable}
The search is initialized by looping over every node $n_x \in V'_0$ with a counter $j$, setting\\
\par
$indexes[0][j] = x$\par
$scores[0][j] = mappingScore(b(n_x), s_0)$\par
$backPointers[0][j] = -1:-1$\\
\par\noindent
Then the nodes $n_x \in V'_i$ for the remaining candidate sets at the indexes $1<=i<=|s|$ are looped over with $j$ as a counter, and $indexes[i][j]$ is set to $x$. For every such entry a list of pairs is made with other indexes $(i', j')$ such that $i'$ is a preceding index $i'<i$ and $j'$ is variable looping over $indexes[i']$. Every entry-pair $((i, j), (i', j'))$ can be scored by a scoring function $\theta((i, j), (i', j'))$. The scoring function works by combining the score contained in the preceding entry, $scores[i'][j']$, a gap penalty, and a mapping score for the current index $mappingScore(n_{indexes[i][j]}, s_i)$. The gap penalty is found by combining a gap penalty for a gap of length $i-i'$ and for a gap of length $distance(n_{indexes[i'][j']}, n_{indexes[i][j]})$. The final score stored in $scores[i][j]$ is the maximal achievable score $\theta$ produced by one of these pairs. $backpointers[i][j]$ is set to the to the index-pair $(i', j')$ responsible for producing this score. The recursive formulas for the three arrays are defined by:\\
\par
$indexes[i][j] = x$\quad for $n_x \in V'_i$\par
$scores[i][j] = \underset{i', j'}{max}$ $\theta((i, j), (i', j'))$\quad for $0$<=$i'$<=$i$, $0$<=$j'$<$length(scores[i'])$\par
$backPointers[i][j] = \underset{i', j'}{arg max}$ $\theta((i, j), (i', j'))$\quad \textcolor{red}{--||--}\par
\par\noindent
where $\theta$ is a scoring function defined as:\\
\par
$\theta((x_1, y_1), (x_2, y_2))=scores[x_2][y_2] + gapPenalty(x_1-x_2) +$\par$ gapPenalty(distance(n_{indexes[x_2][y_2]}, n_{indexes[x_1][y_1]})) + mappingScore(b(n_{indexes[x_1][y_1]}), s_{x_1}))$
\par\noindent
\textcolor{red}{SOMETHING ABOUT FINDING THE HIGHEST SCORE AND BACKPOINTERS. COMPLEXITY ANALYSIS}
\subsubsection{Finding all optimal alignments}
\label{sec:all_optimal_alignments}
\subsection{Handling invalid threshold values}
\section{Merging aligned sequences}
\end{document}