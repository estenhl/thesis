\documentclass[thesis.tex]{subfiles}

\begin{document}
\chapter{Background}
This chapter is divided into three sections. The first is concerned with the biological entities involved throughout the thesis. Because genetics is a huge discipline this chapter will only briefly describe the most critical areas, readers interested in a more thorough introduction are referred to the book ``Introduction to genomics''\cite{introduction_to_genomics}. The second section is directly aimed at the progress in the field of graph-based genomes through discussing relevant articles. Lastly some more general topics of computer science and bioinformatics which play a vital role in the proposed algorithm is presented.
\section{Genetics}
\textit{Deoxyribonucleic acid} (DNA) is a molecular structure in which living organisms store genetic information. The information is encoded by \textit{nucleotides} bound together by a sugar-phosphate backbone into strands. The nucleotides are smaller molecules which vary based on the nitrogenous base they contain: \textit{Adenine} (A), \textit{Cytosine} (C), \textit{Guanine} (G) or \textit{Thymine} (T). Each of the nucleotides has a \textit{complementary base}, A has T and C has G, which it can bind to to form a \textit{base pair}. Due to the chemical structure of the nucleotides, a DNA strand can be said to have a direction: Upstream towards the 5' end or downstream towards the 3' end. The DNA molecule is composed of two reverse complementary which strands are connected in a \textit{double helix} structure. The two strands will have opposing directions, and every base in one of the strands will be connected to its completment. Because either of the strands are easily deduced from the other, DNA is usually represented by only of them. DNA can thus be seen as a linear sequence of discrete units and can be represented by text strings, containing the four leading letters representing nucleotides. The text strings representations often also contain the letter N, referencing \textit{aNy base}. The genetic sequence of an individual is called the \textit{genotype}. Observable traits of the individual is called the \textit{phenotype}.
\subsection{The central dogma}
The process of transforming the genetic information into large functional biomolecules is called \textit{the central dogma} of molecular biology. The central dogma states that DNA is transcribed into \textit{messenger RNA} (mRNA) which in turn is translated into proteins. mRNA is, like DNA, a sequence of nucleotides consisting of the three bases A, C and G and \textit{Uracil} (U) instead of T. The mRNA can be divided into triplets of nucleotides called \textit{codons}. The cell decodes the mRNA codons and create strings of amino acids which are transformed into functional proteins. The relationship between codons and amino acids can be lookep up in a table called \textit{The standard genetic code}\cite[Chapter 1, p. 6]{introduction_to_genomics}. Only a portion of the nucleotides in DNA act as \textit{coding regions} which make it through the transcription process and code for actual protein sequences. These are also called \textit{exons}. The remaining \textit{non-coding regions} of the genetic sequence are known as \textit{introns}. In humans about 1.3\% of the genome is coding regions\cite[Chapter 4]{introduction_to_genomics}, the rest used to be referred to as \textit{junk DNA}. We now know that the non-coding regions also holds important information.
\subsection{Variation}
\label{sec:genetic_variation}
Genetic information is prone to mutations, either as a result of environmental influence or as a consequence of imperfections during DNA transcription. The simplest mutations are \textit{point mutations} which affect a single nucleotide base. Point mutations can either be \textit{Single-nucleotide polymorphisms} (SNPs) where a single base is substituted for another, or \textit{insertions} or \textit{deletions} (indels) where a single nucleotide is removed or inserted into the genetic sequence. Mutations can also occur over larger areas of the genome, where longer subsequences can be deleted, inserted, moved or reversed. A final type of mutations is \textit{Copy number variations}, or \textit{repeats}, where a longer sequence of DNA, typically at least 1 kb \cite{copy_number_variation_new_insights_in_genome_diversity}, is repeated a variable number of times.\\
\par\noindent
As mutations happen randomly to individuals in a population, a diversity of genotypes emerges and creates variability within a \textit{gene pool}. These different genotypes give rise to a variety of phenotypes. A subset of these phenotypes can ensure that an individual is better suited for survival and reproduction than others. Given enough time and scarcity in resources the best suited individuals will survive and pass on their genes to the next generation. This is the process of \textit{natural selection} which is the main driving force behind evolution. Another mechanism in play is \textit{genetic drift} which affects gene frequencies in a gene pool through non-selective, random processes.\textcolor{red}{referanser} \\
\par\noindent
Because there are more possible combinations of nucleotide triplets than there are amino acids there exists some overlap between the codons and the resulting amino acid. For instance the DNA triplets ``CGA'', ``CGC'', ``CGG'',``CGT'', ``AGA'' and ``AGG''  all encode for the amino acid Arginine. In this cases point mutations can occur without affecting the resulting protein. These mutations are called \textit{synonymous}, the opposing case which alters the amino acid sequence are called \textit{non-synonymous}.
\subsection{Reference genomes}
A \textit{reference genome} is a data structure which contains genetic information for a population, typically for a given species. The reference genome has a set of continuous nucleotide sequences, called \textit{contigs}, combined into larger \textit{scaffolds} which again are combined to form the \textit{genome} for a species. The first reference genomes collapsed samples from several individuals into a linear \textit{consensus sequence} which was representable for the species as a whole. Later reference genomes have been built more flexibly to allow positions on the genome, called \textit{loci}, to have several variants, termed \textit{alternate loci}. A specific variant of a gene is called an \textit{allele}. A \textit{haplotype} is a set of alleles which tend to be inherited together. Reference genomes form what can be seen as a dictionary for the genome of a species and can be used in sequencing (Section \ref{sec:sequencing}).
\subsection{The human genome}
The human genome consists of roughly 3 billion base pairs (bp). These base pairs are spread over 46 chromosomes and is assumed to contain about 23 000 genes \cite{introduction_to_genomics}. The current human reference genome is GRCh38\cite{grch38}, developed and maintained by the \textit{Genome Reference Consortium} \cite{genome_reference_consortium}. GRCh38 contains 261 alternate loci, spread over 178 out of a total of 238 regions. An average human is estimated to deviate from the reference genome in 10.000-11.000 synonymous sites and 10.000-12.000 non-synonymous sites \cite{a_map_of_human_genome_variation_from_population_scale_sequencing}.
\subsubsection{Major Histocompatibility Complex}
\label{sec:mhc}
The \textit{Major Histocompatibility Complex} (MHC) is a genetic region spanning approximately 4.5-5 million base pairs (mb)\cite{improved_genome_inference_in_the_mhc_using_a_population_reference_graph}\cite{canonical_stable_general_mapping_using_context_schemes}. In humans it is located on chromosome 6 and contains about 200 genes. MHC is a region known to contain genes which affect the functionality of the immune system \cite{the_importance_of_immune_gene_variability_in_evolutionary_ecology_and_conservation}. Even more so MHC is known to be a highly variable region, containing variants that are directly associated with disease \cite{variation_analysis_and_gene_annotation_of_eight_mhc_haplotypes}. The high variability creates difficulties when comparing DNA sequences to determine genetic causes for the observed disorders.
\section{Bioinformatics}
\subsection{Sequencing}
\label{sec:sequencing}
During \textit{sequencing} a \textit{sequencing machine} is used on a physical DNA fragment to find the underlying nucleotide sequence. The machines produce short \textit{reads}, typically in the order of a hundred bp\cite{sequencing_platforms}, which are combined into longer sequences through a process called \textit{assembly}. When the sequenced individual belongs to a specie with a reference genome, reads are typically mapped to positions in the reference to determine their underlying order in what is called \textit{mapping assembly}. In the opposing case overlap techniques\cite{an_eulerian_path_approach_to_dna_fragment_assembly} or de Bruijn graphs (Section \ref{sec:de_bruijn_graphs}) are often used in what is known as \textit{de novo assembly}\cite[Chapter 1, p. 19]{introduction_to_genomics}.\\
\par\noindent
The different sequencing technologies have varying degrees of errors introduced in their reads, often closely related to the sequencing cost\cite{sequencing_platforms}. The errors can take the form of both point mutations and larger structural variations. Reads produced by sequencing machines are typically prone to contain more errors in their peripherals. There exists efficient strategies for both estimating error rates \cite{estimation_of_sequencing_error_rates_in_short_reads} and correct the reads\cite{error_correction_of_datasets_with_non_uniform_coverage} \textcolor{red}{Can probably provide more citations}.
\subsection{Alignment}
\textit{Sequence alignment} is the process of determining correspondence between text strings, in this case representing DNA, by mapping the elements from one to the elements of the other according to a \textit{substitution matrix} (Fig. \ref{fig:substitution matrix}).
\begin{defn}[Mapping score]
  A score retrieved by mapping to characters $c_1, c_2$ against a substitution matrix. Referenced by $mappingScore(c_1, c_2)$
\end{defn}
The alignment prodecure is never allowed to change the order of the elements in the two strings, but can introduce \textit{gaps}. A gap occurs when one element in one string does not have a counterpart in the opposing string (Fig. \ref{fig:alignments}). When a gap occurs the resulting is penalized according to the length of the gap, by a \textit{gap penalty}. 
\begin{defn}[Gap penalty]
  The penalty recieved for a gap of a given length $l$. Referenced by $gapPenalty(l)$.
\end{defn}
Gap penalties come in different shapes, often according to the origin of the data involved. A \textit{linear gap penalty} gives linear penalties related to the gap length. An \textit{affine gap penalty} distinguishes between opening and continuing a gap. A \textit{logarithmic gap penalty} lets the increase in penalty fade as the gap expands. A schema which provides functionality for mapping bases and penalizing gaps is called a \textit{scoring schema}.
\begin{defn}[Scoring schema]
\label{def:scoring_schema}
A structure which provides a $mappingScore(c_1, c_2)$-function and a $gapPenalty(distance)$-function. The alphabet $\Sigma$ of a scoring schema is defined by the characters present in the scoring schema.
\end{defn}
A gap refers to an element in one of the strings which has no counterpart in the other string when aligned (Fig. \ref{fig:alignments}). The scoring schemas can be based around simple match/mismatch scores, which corresponds to the mathematical \textit{Edit distance problem}, or more complex scores (Fig. \ref{fig:substitution_matrix}). These complex models typically try to model the probabilities behind the physical processes responsible for change. The computational sequence alignment problem consists of finding the highest scoring alignment for any two strings. There exists two main variants of the problem: Finding  \textit{global alignments}, where two entire strings are aligned against each other, and finding \textit{local alignments}, where a string is aligned against a substring of another. The two are traditionally solved respectively by the Needleman-Wunsch and Smith-Waterman algorithms which both are based on \textit{dynamic programming} (Section \ref{sec:dynamic_programming}).\\
\par\noindent
\begin{wrapfigure}{l}{0.3\textwidth}
  \begin{mdframed}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \texttt{ACGGGCCTA}\\
          \texttt{||||\space||||}\\
          \texttt{ACGGACCTA}
        \end{center}
      \end{mdframed}
      \caption{An alignment with no gaps, but one mismatch}
    \end{subfigure}
    \begin{subfigure}[b]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \texttt{ACGGGCCTA}\\
          \texttt{||||\space\space|||}\\
          \texttt{ACGG---CTA}
        \end{center}
      \end{mdframed}
      \caption{An alignment with a single gap of length 2}
    \end{subfigure}
  \end{mdframed}
  \caption{Examples of aligned text strings}
  \label{fig:alignments}
\end{wrapfigure}
If more than two sequences are aligned the result is a \textit{Multiple sequence alignment} (MSA). This is typically done on sequences which is expected to share a common ancestor to determine which traits in the individuals arised from the same origins and how the involved species have diverged genetically over time. A final variant of the alignment problem is one involving large databases of sequences, where the algorithms does not only need to find the best alignment between two sequences, but also determine which sequence should be chosen in order to maximize the result. Both of the preceding techniques typically utilize heuristical methods in order to decrease the computational complexity.
\begin{table}[b]
  \centering
  \caption{The HOXD70 substitution matrix}
  \label{fig:substitution_matrix}
  \makebox[\linewidth]{
    \begin{tabular}{ccccc}
      &\texttt{A}&\texttt{C}&\texttt{G}&\texttt{T}\\ \cline{2-5}
      \texttt{A}&\multicolumn{1}{|c|}{\texttt{91}}&\texttt{-114}&\multicolumn{1}{|c|}{\texttt{-31}}&\multicolumn{1}{c|}{\texttt{-123}}\\ \cline{2-5}
      \texttt{C}&\multicolumn{1}{|c|}{\texttt{-114}}&\texttt{100}&\multicolumn{1}{|c|}{\texttt{-125}}&\multicolumn{1}{c|}{\texttt{-31}}\\ \cline{2-5}
      \texttt{G}&\multicolumn{1}{|c|}{\texttt{-31}}&\texttt{-125}&\multicolumn{1}{|c|}{\texttt{100}}&\multicolumn{1}{c|}{\texttt{-114}}\\ \cline{2-5}
      \texttt{T}&\multicolumn{1}{|c|}{\texttt{-123}}&\texttt{-31}&\multicolumn{1}{|c|}{\texttt{-114}}&\multicolumn{1}{c|}{\texttt{91}}\\ \cline{2-5}
    \end{tabular}}
\end{table}
\clearpage
\subsection{Dynamic programming}
\label{sec:dynamic_programming}
\textit{Dynamic programming} (DP) is a problem-solving technique where a problem instance is solved by combining the results of smaller subproblems. DP is similar to recursion in that every instance is solved by a \textit{recurrence relation} (Equation \ref{eq:ed_recurrence_relation}) which recurses on smaller and smaller problems until a \textit{base case} is found. A base case represent the bottom of the recursion and is a value which can easily be computed without further lookups. The main difference between recursion and DP is that the latter usually stores its intermediate results to allow for fast lookups for reoccuring instances. DP is often used as an approach for optimization problems in order to minimize computational complexity while giving a guarantee for optimal results \cite[Chapter 9]{algorithms_sequential_parallell_and_distributed}.
\begin{wraptable}{r}{0.67\textwidth}
  \begin{center}
    \begin{tabularx}{\textwidth}{ccccccccccc}
      &&a&l&g&o&r&i&t&h&m \\ \cline{2-11}
      &\multicolumn{1}{|c|}{0}&1&\multicolumn{1}{|c|}{2}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&7&\multicolumn{1}{|c|}{8}&\multicolumn{1}{c|}{9}\\ \cline{2-11}
      l &\multicolumn{1}{|c|}{1}&1&\multicolumn{1}{|c|}{1}&2&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
      o &\multicolumn{1}{|c|}{2}&2&\multicolumn{1}{|c|}{2}&2&\multicolumn{1}{|c|}{2}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&\multicolumn{1}{c|}{7}\\ \cline{2-11}
      g &\multicolumn{1}{|c|}{3}&3&\multicolumn{1}{|c|}{3}&2&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
      a &\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
      r &\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{4}&4&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&\multicolumn{1}{c|}{7}\\ \cline{2-11}
      i &\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{5}&5&\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&\multicolumn{1}{c|}{6}\\ \cline{2-11}
      t &\multicolumn{1}{|c|}{7}&6&\multicolumn{1}{|c|}{6}&6&\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&\multicolumn{1}{c|}{5}\\ \cline{2-11}
      h &\multicolumn{1}{|c|}{8}&7&\multicolumn{1}{|c|}{7}&7&\multicolumn{1}{|c|}{7}&6&\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{3}&\multicolumn{1}{c|}{4}\\ \cline{2-11}
      m &\multicolumn{1}{|c|}{9}&8&\multicolumn{1}{|c|}{8}&8&\multicolumn{1}{|c|}{8}&7&\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{4}&\multicolumn{1}{c|}{3}\\ \cline{2-11}
    \end{tabularx}
  \end{center}
  \caption{The 2-dimensional array used for solving the edit distance problem for the strings S=``algorithm'' and P=``logarithm'' (Note: This follows regular ED scoring where every operation is penalized +1)}
  \label{fig:edit_distance_array}
\end{wraptable}
A problem which is typically solved by dynamic programming is the previously mentioned edit distance problem which utilizes a 2-dimensional array to store the computed values (Fig. \ref{fig:edit_distance_array}).For two strings $S$ and $P$, every index $[i,j]$ in the edit distance table represents the problem instance of the strings $S[0:i],P[0:j]$. The base cases can be seen in the first row and column. There are often dropped from the table itself due to the simple nature of their computations. The remainder of the table is filled out with the following recurrence relation:
\begin{equation}
  D[i,j] = min
  \begin{cases}
    D[i-1,j] + 1\\
    D[i,j-1] + 1\\
    D[i-1,j-1] + score(S[i], P[j])
  \end{cases}
  \label{eq:ed_recurrence_relation}
\end{equation}
where $score(x, y)$ is an inverse equality function. The score for the entire problem instance can be found in the cell with the highest indexes in the bottom right corner.\\
\par\noindent
There are two separate ways of using Dynamic Programming. A \textit{bottom-up} approach starts at the smallest cases and computes everything until it reaches the actual given problem instances. This corresponds to starting in the top left corner of the edit distance array and computing the cells iteratively moving downwards to the right. A \textit{top-down} procedure starts at the given problem instance and recursively computes every subproblem that is needed. This means starting in the bottom right corner of the 2-dimensional array and recursing upwards to the right. For the edit distance problem the choice of approach bears no big significance as every cell has to be computed either way, but there are problems where using top-down can avoid some computations which are irrelevant to the final result. The latter can also be efficient for heuristical methods where an area of the search space can be overlooked.
\subsection{Suffix trees}
A \textit{suffix trie} is a special tree constructed for specifically for strings of text, containing vertices representing characters (Fig. \ref{fig:suffix_trie}). Every suffix of a string has a corresponding leaf vertice, where the vertices along path from the root to the vertice contains the characters in the suffix. From this it follows that every substring has a matching path starting in the root node. A \textit{suffix tree}, or \textit{compressed suffix trie}, is a suffix trie in which every linear path is compressed into a single vertice (Fig. \ref{fig:suffix_tree}). Suffix trees can easily be extended to hold collections of strings\cite[Chapter 20]{algorithms_sequential_parallell_and_distributed}. An elementary solution has a space complexity of $O(s)$, where $s$ is the length of the string (or the total length of all strings if the tree is built from a collection), and a string of length $m$ can be looked up in $O(km)$ time for an alphabet of size $k$\cite[Section 20.6.1]{algorithms_sequential_parallell_and_distributed}\\
\par\noindent
\textcolor{red}{A Block-sorting Lossless Data Compression Algorithm}
\begin{figure}[hb]
  \begin{subfigure}[t]{0.49\textwidth}
    \begin{mdframed}
      \begin{center}
        \begin{tikzpicture}
          \node[state,scale=0.8] (q0) {};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q0] (q1) {$a$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q0] (q2) {$n$};
          \node[state,scale=0.8] [left=0.25cm of q1] (q3) {$b$};
          \node[state,scale=0.8] [right=0.25cm of q2] (q4) {$s$};
          \node[state,scale=0.8] [below left=0.6 and -0.05cm of q3] (q5) {$a$};
          \node[state,scale=0.8] [below left=0.6 and -0.05cm of q1] (q6) {$n$};
          \node[state,scale=0.8] [below right=0.6 and -0.05cm of q1] (q7) {$s$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q2] (q8) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q5] (q9) {$n$};
          \node[state,scale=0.8] [below=0.36cm of q6] (q10) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q8] (q11) {$n$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q8] (q12) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q9] (q13) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q10] (q14) {$n$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q10] (q15) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q11] (q16) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q13] (q17) {$n$};
          \node[state,scale=0.8] [below=0.36cm of q14] (q18) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q16] (q19) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q17] (q20) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q18] (q21) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q20] (q22) {$s$};

          \path 
          (q0) edge node {} (q1)
          edge node {} (q2)
          edge node {} (q3)
          edge node {} (q4)
          (q3) edge node {} (q5)
          (q1) edge node {} (q6)
          edge node {} (q7)
          (q2) edge node {} (q8)
          (q5) edge node {} (q9)
          (q6) edge node {} (q10)
          (q8) edge node {} (q11)
          edge node {} (q12)
          (q9) edge node {} (q13)
          (q10) edge node {} (q14)
          edge node {} (q15)
          (q11) edge node {} (q16)
          (q13) edge node {} (q17)
          (q14) edge node {} (q18)
          (q16) edge node {} (q19)
          (q17) edge node {} (q20)
          (q18) edge node {} (q21)
          (q20) edge node {} (q22);
        \end{tikzpicture}
      \end{center}
    \end{mdframed}
    \caption{}
    \label{fig:suffix_trie}
  \end{subfigure}
  \begin{minipage}[t]{0.49\textwidth}
  \begin{subfigure}[t]{\textwidth}
    \begin{mdframed}
      \begin{center}
        \begin{tikzpicture}
          \node[state,scale=0.8] (q0) {};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q0] (q1) {$a$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [left=0.25cm of q1] (q3) {$bananas$};
          \node[state,scale=0.8] (q3) [below right=0.6cm and -0.05cm of q0] (q4) {$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [right=0.5cm of q4] (q2) {$na$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q1] (q5) {$na$};
          \node[state,scale=0.8] (q6) [below right=0.6cm and -0.05cm of q1]{$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q2] (q7) {$nas$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q2] (q8) {$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q5] (q9) {$nas$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q5] (q10) {$s$};

          \path
          (q0) edge node {} (q1)
          edge node {} (q2)
          edge node {} (q3)
          edge node {} (q4)
          (q1) edge node {} (q5)
          edge node {} (q6)
          (q2) edge node {} (q7)
          edge node {} (q8)
          (q5) edge node {} (q9)
          edge node {} (q10);
        \end{tikzpicture}
      \end{center}
    \end{mdframed}
    \caption{}
    \label{fig:suffix_tree}
  \end{subfigure}
  \begin{minipage}[t]{0.49\textwidth}
    \caption{The suffix tree (a) and suffix trie  (b) of the string ``bananas''}
  \end{minipage}
  \end{minipage}
  \label{fig:suffix_trees}
\end{figure}
\clearpage
\section{Graph-based genome representations}
Representing genetic information as graphs instead of the traditional linear representations have some major advantages. Graphs are far more expressive structures compared to text strings, able to represent more complex relationships between the elements involved. Secondly, if biological questions can be rephrased to graph theoretical settings, the extensive mathematical field of graph theory can present more feasible approaches to previously hard problems. There is however a major problem: A more complex structure calls for more sophisticated variants of existing methods. Graph-based approaches have been used for some time in the assembly process, and more recently in relation to reference genomes. This section will present both of these approaches alongside some of the remaining unsolved problems. The section is presented in a way which should not require any previous knowledge of graph theory except for elementary terms, but readers interested in a more complete introduction is referred to the bibliography \cite[Chapter 0]{introduction_to_the_theory_of_computation} \cite[Chapter 9]{data_structures_and_algorithm_analysis_in_java} \cite[Chapter 11]{algorithms_sequential_parallell_and_distributed}. Complexity in regards to the graphs and their operations is discussed using \textit{big-O} notation \cite[Chapter 2]{data_structures_and_algorithm_analysis_in_java}\cite[Section 3.1]{algorithms_sequential_parallell_and_distributed}
\subsection{Representation}
\begin{wrapfigure}{r}{0.65\textwidth}
  \begin{mdframed}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=1.4cm]
            \node[state] (q0) {$start$};
            \node[state] [above right of=q0] (q1) {$A$};
            \node[state] [below right of=q0] (q2) {$C$};
            \node[state] [right of=q1] (q3) {$G$};
            \node[state] [right of=q2] (q4) {$T$};
            \node[state] [below right of=q3] (q5) {$end$};

            \path (q0) edge[->] node {} (q1)
            edge[->] node {} (q2)
            edge[->] node {} (q3)
            edge[->] node {} (q4)
            edge[->] node {} (q5)
            (q1) edge[<->] node {} (q2)
            edge[loop above] node {} (q1)
            edge[<->] node {} (q3)
            edge[<->] node {} (q4)
            edge[->] node {} (q5)
            (q2) edge[<->] node {} (q3)
            edge[loop below] node {} (q2)
            edge[<->] node {} (q4)
            edge[->] node {} (q5)
            (q3) edge[<->] node {} (q4)
            edge[loop above] node {} (q3)
            edge[->] node {} (q5)
            (q4) edge[->] node {} (q5)
            edge[loop below] node {} (q4);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{A graph with paths corresponding to every possible DNA string}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.25cm]
            \node[state,scale=0.7] (q0) {$start$};
            \node[state,scale=0.7] [right =0.3cm of q0] (q1) {$A$};
            \node[state,scale=0.7] [right of=q1] (q2) {$G$};
            \node[state,scale=0.7] [right of=q2] (q3) {$C$};
            \node[state,scale=0.7] [right of=q3] (q4) {$T$};
            \node[state,scale=0.7] [right of=q4] (q5) {$C$};
            \node[state,scale=0.7] [right=0.3cm of q5] (q6) {$end$};
            \node[state,scale=0.7] [above of=q1] (q7) {$A$};
            \node[state,scale=0.7] [right of=q7] (q8) {$G$};
            \node[state,scale=0.7] [right of=q8] (q9) {$G$};
            \node[state,scale=0.7] [right of=q9] (q10) {$T$};
            \node[state,scale=0.7] [right of=q10] (q11) {$C$};
            \node[state,scale=0.7] [below of=q1] (q12) {$A$};
            \node[state,scale=0.7] [right of=q12] (q13) {$G$};
            \node[state,scale=0.7] [right of=q13] (q14) {$C$};
            \node[state,scale=0.7] [right of=q14] (q15) {$T$};
            \node[state,scale=0.7] [right of=q15] (q16) {$C$};

            \path (q0) edge node {} (q1)
            edge node {} (q7)
            edge node {} (q12)
            (q1) edge node {} (q2)
            (q2) edge node {} (q3)
            (q3) edge node {} (q4)
            (q4) edge node {} (q5)
            (q5) edge node {} (q6)
            (q7) edge node {} (q8)
            (q8) edge node {} (q9)
            (q9) edge node {} (q10)
            (q10) edge node {} (q11)
            (q11) edge node {} (q6)
            (q12) edge node {} (q13)
            (q13) edge node {} (q14)
            (q14) edge node {} (q15)
            (q15) edge node {} (q16)
            (q16) edge node {} (q6);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{A graph which is built through alignments without allowing variation}
    \end{subfigure}
  \end{mdframed}
  \caption{Two sequence graphs displaying too much flexibility (a) and (arguably) too much rigidity (b)}
  \label{fig:flexibility_rigidness_tradeoff}
\end{wrapfigure}
Deciding upon the representation of the graph consists of defining the structure of the elements involved, namely the vertices and edges. As the graphs are built from genetic information the basic building blocks, the nucleotides, should obviously be represented. If the input data are more complex than single nucleotides, we must represent the relationships. Because the input data has variation, the structure needs to tolerate flexibility. There is however a risk of making the structures so flexible they present no consistency, and a flexibility/rigidness-tradeoff becomes apparent (Fig. \ref{fig:flexibility_rigidness_tradeoff}). How the structures are defined in detailed should be determined through the operations which are desirable to perform on them.
\subsubsection{De Bruijn graphs}
\label{sec:de_bruijn_graphs}
In the article ``An Eulerian path approach to DNA fragment assembly''\cite{an_eulerian_path_approach_to_dna_fragment_assembly}, Pevzner, Tang and Waterman proposes \textit{de Bruijn} graphs as a solution to find the correct assembly of repeats during fragment assembly. A de Bruijn graph is a structure where vertices represent \textit{k-mers} from an alphabet and edges represent relationships between the k-mers of two vertices (Fig. \ref{fig:de_bruijn_graph}). Pevzner et al. lets the vertices contain strings of length $l-1$ and connects vertices with an edge wherever there exists a read of length $l$ containing the two substrings. Formulating the problem in this fashion lets the problem be formulated as a \textit{Eulerian path} problem, solvable in polynomial time, rather than the traditional ``overlap-layout-consensus'' method which is equivalent to the NP-complete problem of finding a \textit{Hamiltonian path}\cite[Section 11.1]{algorithms_sequential_parallell_and_distributed}. A great benefit with de Bruijn graphs is that there is no disambiguity: Any legal k-mer has at no point more than one vertice representing it.\\
\begin{figure}[H]
  \begin{mdframed}
    \begin{center}
      \begin{tikzpicture}[->,auto,node distance=1.5cm]
        \node[state] (q0) {$ACG$};
        \node[state] [right of=q0] (q1) {$CGT$};
        \node[state] [right of=q1] (q2) {$GTT$};
        \node[state] [right of=q2] (q3) {$TTT$};
        \node[state] [right of=q3] (q4) {$TTA$};
        \node[state] [right of=q4] (q5) {$TAC$};
        \node[state] [right of=q5] (q6) {$ACG$};

        \path (q0) edge node {} (q1)
        (q1) edge node {} (q2)
        (q2) edge node {} (q3)
        (q3) edge node {} (q4)
        (q4) edge node {} (q5)
        (q5) edge node {} (q6);
      \end{tikzpicture}
    \end{center}
  \end{mdframed}
  \caption{A de Bruijn graph with $k=3$ corresponding to the sequence ACGTTTACG}
  \label{fig:de_bruijn_graph}
\end{figure}
\par\noindent
A more detailed type of de Bruijn graphs is the colored variant where the origins of edges and vertices are stored as colors. The entire sequence originating from a single individual sample can be seen by following a path with a given color. Similarities between samples can be seen as multicolored stretches, variation take the form of bubbles. Colored de Bruijn graphs can be used for de novo assembly as a more powerful method for detecting variation, compared to traditional assembly techniques\cite{de_novo_assembly_and_genotyping_of_variants_using_colored_de_bruijn_graphs}.
\subsubsection{Sequence graphs}
The relationship between a de Bruijn graph and the sequences it represents is not immediately apparent. A more intuitively pleasing representation is a graph where every vertice contains exactly one nucleotide (Figure \textcolor{red}{figure}), a concept called \textit{partially ordered graphs} by Lee et al.\cite{improved_genome_inference_in_the_mhc_using_a_population_reference_graph} and \textit{sequence graphs} by Paten et al.\cite{mapping_to_a_reference_genome_structure}. In this representation the underlying connection between the characters of a text string and the vertices of the graph is more obvious. The representation does however have a major drawback compared to de Bruijn graphs: The concept of uniqueness. A vertice can no longer be identified solely by the data it contains. To solve this problem the vertices can be given ids, for instance UUIDs\cite{mapping_to_a_reference_genome_structure}, for uniqueness. Even though these ids can be used to identify a vertice they contain no information regarding the data which is stored in the graph. The difficulties presented by this problem will be the basis for the subsequent section on mapping. 
\subsubsection{Cactus graphs}
The article ``Cactus Graphs for Genome Comparisons'' introduces cactus graphs as a model for alignment of multiple genomes. A cactus graph has vertices representing sets of homologous DNA sequences and edges representing adjacendies between the strings in any of the genomes used as input (Fig. \textcolor{red}{figure}). In cases where there exists several adjacencies between two vertices these are combined into a single edge with several labels. The result is a graph where every \textit{simple cycle}, cycles where no vertice is repeated, has at most one vertice in common. A similarity between this representation and de Bruijn graphs is that the vertices contain subsequences of the original input sequences. Additionally this representations allows some flexibility, controllable through the definition of homology. If the strictest possible restriction is set, a restriction which requires equal strings, the vertices would contain an exact k-mer from an input sequence just like the de Bruijn vertices. 
\subsection{Mapping}
Although the two terms are often used isomorphically we will in this thesis define mapping and alignment as two separate concepts. Mapping is the process of finding relationships between single characters of a string and single elements of a reference genome. Alignment is concerned with finding relationships between consecutive elements of an input string and substructures in the reference genome. For linear strings mapping is easy. Every string has the same underlying coordinate system, represented by the positions of the characters, and two elements from two separate sequences are either in the same position or they are not. If they are not the difference in position can be derived from the difference between the indexes. Because the indexes of a graph has only one property, uniqueness, they do not hold the intrinsic value of describing relationships between vertices. Any mapping system which uses fixed coordinates would face problems when dealing with a fluent graph able to merge in new information, as the internal relations are bound to change. In de Bruijn graphs the problem is solved by moving the mappable quality away from positions and into the data: For any possible k-mer there either is a corresponding vertice or there is not. In sequence graphs, where nucleotides are the most basic information, there exists an equal number of identically scoring positions for every base as there are vertices containing that vertice in the graph.\\
\par\noindent
Paten et al.\cite{mapping_to_a_reference_genome_structure} introduce the concept of \textit{context-based mapping} as a solution to the mapping problem when the reference is modeled as a graph. Context-based mapping is an approach where a vertice is identified by the surrounding environment in the graph. More technically a vertice has a set of \textit{contexts} which are tuples (L, B, R). The L references the left side, a path going in to the vertice, B is the base contained in the vertice and R is an outgoing path from the vertice (Fig. \textcolor{red}{figure}). More conceptually, contexts can be seen as paths which pass through a given vertice. Because these paths are linear and passes through vertices containing characters, the contexts can be treated as text strings. There are two concrete examples of approaches presented in the article: The \textit{general left-right exact match mapping scheme} and the \textit{central exact match mapping scheme}. The key words left-right and central refer to how a vertice defines its contexts based on the surrondings. The former defines separate contexts for incoming and outcoming paths whereas the latter defines the vertice as a center of a path where the differences of the lengths of the two contexts are minimized. A  \textit{balanced central exact match mapping scheme} is a special case of the latter where both contexts are the same length, and the vertice thus is the center of a k-mer. This is a concept closely related to de Bruijn graphs.\\
\par\noindent
Both of the examples use the word \textit{exact} in their definitions. The term refers to the fact that every context is \textit{unique} to a single vertice which means every possible context either maps unambiguously to a single vertice or does not map at all. Because the graphs have the possibility of branching a vertice can have several contexts contained in \textit{context sets}. Because every context is unique a collection of such will also be unique, which means context-based mapping leads to a unique two-way mapping schema. This is an even stronger notion of mappability than positions is strings, as a character of a string does not necessarily map uniquely back to its position. Being this precise in the definition has a drawback: If a vertice does not have a unique context it is no longer mappable. 
\subsection{Alignment}
As previously discussed, alignment of text strings has for some time been considered a solved problem. We let the two strings represent each their dimension in a two-dimensional space and search for a path through the space which yields an optimal score. When one of the strings is replaced with a graph a simple one-dimensional representation is no longer sufficient. There does not exist a simple ``3 steps before'' or ``11 steps after'' relationship between the elements involved. A solution to this problem can be to imagine alignments agains graphs like alignments against sequences in a database: There exists several possible sequences which can be aligned two-dimensionally, find the one yielding the highest score. But, unlike individual sequences in a database, the paths through a graph can have overlapping regions. Creating all possible paths results in an exponential number of possibilities which does not necessarily portray a fair picture of the underlying structure.
\subsubsection{Dynamic programming on graphs}
The article ``Multiple sequence alignment using partial order graphs'' proposes a direct adaptation of the regular two-dimensional dynamic programming solution for graphs. Every vertice contains a one-dimensional array representing the string which is aligned. Just like an array-index in the edit distance problems, the vertice looks at smaller subproblems to decide what the values of the array should be. However, because this is a graph and not a string, we have no preceding indexes to look up. The vertice has to look at every preceding vertice as a single instance of the two-dimensional problem, to determine which of the incoming vertices represents the linear path which presents the highest score. After filling out every index $i$ of the array in the vertice $v$ in this fashion, the array represents the highest score possible for the substring up to index $s$ for all paths up to vertice $v$.\\
\par\noindent
Using an approach which is this closely related to the known approaches for regular string alignment has its advantages. Alignments and scores are verifiable through existing tools and the principle of optimality is contained through the dynamic programming. Techniques for handling the different types of alignments, for instance local or global, can be inherited from the domain of strings. The algorithm is however susceptible to the inherent complexity of graphs.
\label{sec:po_msa}
\subsubsection{Context-based alignment}
In the article ``Canonical, Stable, General Mapping using Context Schemes''\cite{canonical_stable_general_mapping_using_context_schemes} the concept of context-based mapping is used for aligning strings. The algorithm works by identifying substrings of the input string which maps uniquely to a context in the reference. Overlapping contexts are combined into longer \textit{Maximal Unique Substrings} (MUMs) which uniquely align to a region of the reference. Finally the aligned substrings are combined in chains into $\beta$-synteny blocks, paths along the graph where exactly $\beta$ mismatches are allowed between the uniquely mapped elements. Any remaining bases are mapped \textit{on credit}, for instance as a graph search through the region represented by the gap between the end and start of to consecutive uniquely mapped sequences. The conceptual idea is that any string mapping to a region of the graph should share a number of unique paths, which can be combined into a larger result. The authors name their heuristical approach the \textit{$\alpha-\beta$-Natural Context-Driven Mapping Scheme} where the $\alpha$ refers to the level of uniqueness required in a context to be considered unique and the $\beta$ refers to the degree of similarity between a substring and a context in order to classifiy the two as equal.
\section{Tools and frameworks}
\subsection{Graph representations}
\subsection{Generics in java}
\subsection{Visualizing graphs: The dot-format}
\end{document}

















