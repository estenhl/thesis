\documentclass[thesis.tex]{subfiles}

\begin{document}
\chapter{Background}
\section{Genetics}
\textit{Deoxyribonucleic acid} (DNA) is a molecule in which living organisms store genetic information. The information is encoded by \textit{nucleotides} bound together by a sugar-phosphate backbone into strands. The nucleotides are smaller molecules which contain one of the nitrogenous bases \textit{Adenine} (A), \textit{Cytosine} (C), \textit{Guanine} (G) or \textit{Thymine} (T). \textcolor{red}{Each of the bases are complementary to another, A with T and C with G}. Due to the chemical structure of the nucleotides, a DNA strand can be said to have a direction: Upstream towards the 5' end or downstream towards the 3' end. DNA strands can be connected with a \textit{reverse complementary} strand in a double helix. The two strands will have opposing directions, and every base in one of the strands will be connected to its complement. The paired nucleotides are called \textit{base pairs}. Because either of the strands are easily deduced from the other, DNA is usually represented by only of them. DNA can be seen as a linear sequence of discrete units and can thus be represented by text strings, containing the four leading letters representing nucleotides. The text strings representations often also contain the letter N, referencing \textit{aNy base}.
\subsection{Genes}
\textcolor{red}{"What is a gene?" Helen Pearson. Coding/non-coding, synonymous/non-synonymous}
\subsection{Variation}
\label{sec:genetic_variation}
Genetic information is prone to mutations, either as a result of environmental influence or as a consequence of imperfections in reproduction. The simplest mutations are \textit{point mutations} which affect a single nucleotide base. Point mutations can either be \textit{Single-nucleotide polymorphisms} (SNPs) where a single base is substituted for another, or \textit{insertions} or \textit{deletions} (indels) where a single nucleotide is removed or inserted into the genetic sequence. Mutations can also occur over larger areas of the genome, where longer subsequences can be deleted, inserted, moved or reversed. A final type of mutations is \textit{Copy number variations} where a longer sequence of DNA, typically at least 1 kb \cite{copy_number_variation_new_insights_in_genome_diversity}, is repeated a variable number of times. CNVs are also called \textit{repeats}\\
\par\noindent
\textcolor{red}{Evolution, genetic drift}
\subsection{A reference genome}
\textcolor{red}{contigs, scaffold, chromosomes. Haplotypes}
\subsection{The human genome}
The human genome consists of roughly 3 billion base pairs (bp). These base pairs are spread over 22 paired chromosomes and is assumed to contain about 23 000 genes \cite{introduction_to_genomics}. The current human reference genome is GRCh38, developed and maintained by the \textit{Genome Reference Consortium} \textcolor{red}{HOWTO: reference websites}. GRCh38 contains 261 alternate loci, spread over 178 out of a total of 238 regions. An average human is estimated to deviate from the reference genome in 10.000-11.000 synonymous sites and 10.000-12.000 non-synonymous sites.
\subsubsection{Major Histocompatibility Complex}
\label{sec:mhc}
The \textit{Major Histocompatibility Complex} (MHC) is a genetic region spanning approximately 4 million base pairs (mb) \cite{immunobiology_the_immune_system_in_health_and_disease}. In humans it is located on chromosome 6 and contains about 200 genes. MHC is a region known to contain genes which affect the functionality of the immune system \cite{the_importance_of_immune_gene_variability_in_evolutionary_ecology_and_conservation}. Even more so MHC is known to be a highly variable region, containing variants that are directly associated with disease \cite{variation_analysis_and_gene_annotation_of_eight_mhc_haplotypes}.
\subsection{Sequencing}
\label{sec:sequencing}
\textcolor{red}{Read. de-novo/mapping assembly. Read errors and correction}
\subsection{Alignment}
\textit{Sequence alignment} is the process of determining correspondence between text strings, in this case representing DNA, by mapping the elements from one to the elements of the other. The score of an alignment is determined by a \textit{scoring schema}, which provides scores for mapping characters against characters through a \textit{substitution matrix} and penalties for introducing \textit{gaps}. 
\begin{defn}[Scoring schema]
A structure which provides functionality for mapping bases against bases with a function $mappingScore(c_1, c_2)$ and for penalizing gaps with a function $gapPenalty(distance)$. The structure is defined through a substitution matrix, a gap opening penalty and a gap extension penalty
\end{defn}
\begin{defn}[Consistent scoring schema]
A scoring schema is consistent if $mappingScore(c, c) = \underset{a \in \Sigma}{max} (mappingScore(c, a))$ for all $c \in \Sigma$.
\end{defn}
A gap refers to an element in one of the strings which has no counterpart in the other string when aligned (Fig. \ref{fig:alignments}). The scoring schemas can be based around simple match/mismatch scores, which corresponds to the mathematical \textit{Edit distance problem}, or more complex scores (Fig. \ref{fig:substitution_matrix}). These complex models typically try to model the probabilities behind the physical processes responsible for change. The computational sequence alignment problem consists of finding the highest scoring alignment for any two strings. There exists two main variants of the problem, \textit{global alignments} where two entire strings are aligned against each other and \textit{local alignments} where a string is aligned against a substring of another. The two are traditionally solved respectively by the Needleman-Wunsch and Smith-Waterman algorithms which both are based on \textit{dynamic programming} (Section \ref{sec:dynamic_programming}).
\begin{wrapfigure}{L}{0.3\textwidth}
  \begin{subfigure}[t]{\textwidth}
    \begin{mdframed}
      \begin{center}
        \texttt{ACGGGCCTA}\\
        \texttt{||||\space||||}\\
        \texttt{ACGGACCTA}
      \end{center}
    \end{mdframed}
    \caption{An alignment with no gaps, but one mismatch}
  \end{subfigure}
  \begin{subfigure}[b]{\textwidth}
    \begin{mdframed}
      \begin{center}
        \texttt{ACGGGCCTA}\\
        \texttt{||||\space\space|||}\\
        \texttt{ACGG---CTA}
      \end{center}
    \end{mdframed}
    \caption{An alignment with a single gap of length 2}
  \end{subfigure}
  \caption{Examples of aligned text strings}
  \label{fig:alignments}
\end{wrapfigure}
\par\noindent
If more than two sequences are aligned the result is a \textit{Multiple sequence alignment} (MSA). This is typically done on sequences which is expected to share a common ancestor to determine which traits of the individuals arised from the same origins and how the involved species have diverged over time. A final variant of the alignment problem is one involving large databases of sequences, where the algorithms does not only need to find the best alignment between two sequences, but also determine which sequence should be chosen in order to maximize the result. Both of the preceding techniques utilize heuristical methods to decrease the computational complexity.
\begin{figure}[b]
    \begin{center}
      \begin{tabularx}{\linewidth}{ccccc}
        &\texttt{A}&\texttt{C}&\texttt{G}&\texttt{T}\\ \cline{2-5}
        \texttt{A}&\multicolumn{1}{|c|}{\texttt{91}}&\texttt{-114}&\multicolumn{1}{|c|}{\texttt{-31}}&\multicolumn{1}{c|}{\texttt{-123}}\\ \cline{2-5}
        \texttt{C}&\multicolumn{1}{|c|}{\texttt{-114}}&\texttt{100}&\multicolumn{1}{|c|}{\texttt{-125}}&\multicolumn{1}{c|}{\texttt{-31}}\\ \cline{2-5}
        \texttt{G}&\multicolumn{1}{|c|}{\texttt{-31}}&\texttt{-125}&\multicolumn{1}{|c|}{\texttt{100}}&\multicolumn{1}{c|}{\texttt{-114}}\\ \cline{2-5}
        \texttt{T}&\multicolumn{1}{|c|}{\texttt{-123}}&\texttt{-31}&\multicolumn{1}{|c|}{\texttt{-114}}&\multicolumn{1}{c|}{\texttt{91}}\\ \cline{2-5}
      \end{tabularx}
    \end{center}
  \caption{The HOXD70 substitution matrix}
  \label{fig:substitution_matrix}
\end{figure}
\clearpage
\section{Graph-based genome representations}
Representing genetic information as graphs instead of the traditional linear representations have some major advantages. Graphs are far more expressive structures compared to text strings, able to represent more complex relationships between the elements involved. Secondly, if biological questions can be rephrased to graph theoretical settings, the extensive mathematical field of graph theory can present more feasible approaches to previously hard problems. There is however a major problem: A more complex structure calls for more sophisticated variants of existing methods. Graph-based approaches have been used for some time in the assembly process, and more recently in relation to reference genomes. This section will present both of these approaches alongside some of the remaining unsolved problems. No graph theoretical foreknowledge is needed as all the involved elements will be defined before they are used, but for interested readers there exists good sources in the bibliography \cite[Chapter 0]{introduction_to_the_theory_of_computation} \cite[Chapter 9]{data_structures_and_algorithm_analysis_in_java} \cite[Chapter 11]{algorithms_sequential_parallell_and_distributed}. Complexity in regards to the graphs and their operations is discussed using \textit{big-O} notation \cite[Chapter 2]{data_structures_and_algorithm_analysis_in_java}\cite[Section 3.1]{algorithms_sequential_parallell_and_distributed}
\begin{defn}[Graph-based reference genome (Graph)]
  A pair $G=\{V,E\}$ where $V$ is a set of vertices and $E$ is a set of edges. $|G|$ denotes the number of vertices in $G$.
\end{defn}
\subsection{Representation}
Deciding upon the representation of the graph consists of defining the structure of the elements involved, namely the vertices and edges. As the graphs are built from genetic information the basic building blocks, the nucleotides, should obviously be represented. If the input data are more complex than single nucleotides, we must represent the relationships. Because the input data has variation, the structure needs to tolerate flexibility. There is however a risk of making the structures so flexible they present no consistency, and a flexibility/rigidness-tradeoff becomes apparent (fig. \ref{fig:flexibility_rigidness_tradeoff}). How the structures are defined in detailed should be determined through the operations which are desirable to perform on them.\\
\par\noindent
\begin{wrapfigure}{L}{0.65\textwidth}
  \begin{mdframed}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=1.4cm]
            \node[state] (q0) {$start$};
            \node[state] [above right of=q0] (q1) {$A$};
            \node[state] [below right of=q0] (q2) {$C$};
            \node[state] [right of=q1] (q3) {$G$};
            \node[state] [right of=q2] (q4) {$T$};
            \node[state] [below right of=q3] (q5) {$end$};

            \path (q0) edge[->] node {} (q1)
            edge[->] node {} (q2)
            edge[->] node {} (q3)
            edge[->] node {} (q4)
            edge[->] node {} (q5)
            (q1) edge[<->] node {} (q2)
            edge[loop above] node {} (q1)
            edge[<->] node {} (q3)
            edge[<->] node {} (q4)
            edge[->] node {} (q5)
            (q2) edge[<->] node {} (q3)
            edge[loop below] node {} (q2)
            edge[<->] node {} (q4)
            edge[->] node {} (q5)
            (q3) edge[<->] node {} (q4)
            edge[loop above] node {} (q3)
            edge[->] node {} (q5)
            (q4) edge[->] node {} (q5)
            edge[loop below] node {} (q4);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{A graph with paths corresponding to every possible DNA string}
    \end{subfigure}
    \begin{subfigure}[t]{\textwidth}
      \begin{mdframed}
        \begin{center}
          \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1.25cm]
            \node[state,scale=0.7] (q0) {$start$};
            \node[state,scale=0.7] [right =0.3cm of q0] (q1) {$A$};
            \node[state,scale=0.7] [right of=q1] (q2) {$G$};
            \node[state,scale=0.7] [right of=q2] (q3) {$C$};
            \node[state,scale=0.7] [right of=q3] (q4) {$T$};
            \node[state,scale=0.7] [right of=q4] (q5) {$C$};
            \node[state,scale=0.7] [right=0.3cm of q5] (q6) {$end$};
            \node[state,scale=0.7] [above of=q1] (q7) {$A$};
            \node[state,scale=0.7] [right of=q7] (q8) {$G$};
            \node[state,scale=0.7] [right of=q8] (q9) {$G$};
            \node[state,scale=0.7] [right of=q9] (q10) {$T$};
            \node[state,scale=0.7] [right of=q10] (q11) {$C$};
            \node[state,scale=0.7] [below of=q1] (q12) {$A$};
            \node[state,scale=0.7] [right of=q12] (q13) {$G$};
            \node[state,scale=0.7] [right of=q13] (q14) {$C$};
            \node[state,scale=0.7] [right of=q14] (q15) {$T$};
            \node[state,scale=0.7] [right of=q15] (q16) {$C$};

            \path (q0) edge node {} (q1)
            edge node {} (q7)
            edge node {} (q12)
            (q1) edge node {} (q2)
            (q2) edge node {} (q3)
            (q3) edge node {} (q4)
            (q4) edge node {} (q5)
            (q5) edge node {} (q6)
            (q7) edge node {} (q8)
            (q8) edge node {} (q9)
            (q9) edge node {} (q10)
            (q10) edge node {} (q11)
            (q11) edge node {} (q6)
            (q12) edge node {} (q13)
            (q13) edge node {} (q14)
            (q14) edge node {} (q15)
            (q15) edge node {} (q16)
            (q16) edge node {} (q6);
          \end{tikzpicture}
        \end{center}
      \end{mdframed}
      \caption{A graph which is built through alignments without allowing variation}
    \end{subfigure}
  \end{mdframed}
  \caption{Two graphs with vertices representing nucleotides and edges representing sequences displaying too much flexibility (a) and (arguably) too much rigidity (b)}
  \label{fig:flexibility_rigidness_tradeoff}
\end{wrapfigure}
\subsubsection{de Bruijn graphs}
In the article ``An Eulerian path approach to DNA fragment assembly''\cite{an_eulerian_path_approach_to_dna_fragment_assembly}, Pevzner, Tang and Waterman proposes \textit{de Bruijn} graphs as a solution to find the correct assembly of repeats during fragment assembly. A de Bruijn graph is a structure where vertices represent \textit{k-mers} from an alphabet and edges represent relationships between the k-mers of two vertices (Fig. \ref{fig:de_bruijn_graph}). Pevzner et al. lets the vertices contain strings of length $l-1$ and connects vertices with an edge wherever there exists a read of length $l$ containing the two substrings. Formulating the problem in this fashion lets the problem be formulated as a \textit{Eulerian path} problem, solvable in polynomial time, rather than the traditional ``overlap-layout-consensus'' method which is equivalent to the NP-complete problem of finding a \textit{Hamiltonian path}\cite[Section 11.1]{algorithms_sequential_parallell_and_distributed}. A great benefit with de Bruijn graphs is that there is no disambiguity: Any legal k-mer has at no point more than one vertice representing it.
\begin{figure}
    \begin{mdframed}
      \begin{center}
        \begin{tikzpicture}[->,auto,node distance=1.5cm]
          \node[state] (q0) {$ACG$};
          \node[state] [right of=q0] (q1) {$CGT$};
          \node[state] [right of=q1] (q2) {$GTT$};
          \node[state] [right of=q2] (q3) {$TTT$};
          \node[state] [right of=q3] (q4) {$TTA$};
          \node[state] [right of=q4] (q5) {$TAC$};
          \node[state] [right of=q5] (q6) {$ACG$};

          \path (q0) edge node {} (q1)
          (q1) edge node {} (q2)
          (q2) edge node {} (q3)
          (q3) edge node {} (q4)
          (q4) edge node {} (q5)
          (q5) edge node {} (q6);
        \end{tikzpicture}
      \end{center}
    \end{mdframed}
  \caption{A de Bruijn graph with $k=3$ corresponding to the sequence ACGTTTACG}
  \label{fig:de_bruijn_graph}
\end{figure}
\par\noindent
A more detailed type of de Bruijn graphs is the colored variant where the origins of edges and vertices are stored as colors. The entire sequence originating from a single individual sample can be seen by following a path with a given color. Similarities between samples can be seen as multicolored stretches, variation take the form of bubbles. Colored de Bruijn graphs can be used for de novo assembly as a more powerful method for detecting variation, compared to traditional assembly techniques\cite{de_novo_assembly_and_genotyping_of_variants_using_colored_de_bruijn_graphs}.
\subsubsection{Sequence graphs}
The term \textit{sequence graph} stems from the article ``Mapping to a Reference Genome structure''\cite{mapping_to_a_reference_genome_structure} and describes a graph structure which is possibly more intuitively pleasing. Every vertice in the graph corresponds to a single nucleotide from one or more genetic sequences used in building the graph. An edge represents two nucleotides which are consecutive in one of the original sequences. Paths symbolize subsequences of the originating input sequences. To handle the arising problem that the contents of nodes are no longer unique each vertice can be given an index which is exclusive for their associated graph. Whenever a graph is referenced without being specifically classified the following definitions are assumed:\\
\begin{defn}[Graph genome vertice (Vertice)]
  A pair $v=\{b, i\}$ where $b \in \{A, C, T, G\}$ and $i$ is a unique index. The vertice at index $i$ is denoted $v_i$. Every graph $G$ also has two special vertices $s_G=\{s, 0\}$ and $t_G=\{e, -1\}$ which represents unique start and end vertices. The notation $b(v_i)$ references the first element in the pair (the nucleotide).
\end{defn}
\begin{defn}[Graph genome edge (Edge)]
  An ordered pair $e=\{i_s, i_e\}$ where both elements are indexes for vertices. 
\end{defn}
\begin{defn}[Path]
  An ordered list $P$ of indexes such that for all consecutive ordered pairs $\{i_x, i_{x+1}\} \in P$ there exists an edge $e=\{i_x, i_{x+1}\}$.
\end{defn}
\subsection{Mapping}
Although the two terms are often used isomorphically we will in this thesis define mapping and alignment as two separate concepts. Mapping is the process of finding relationships between single characters of a string and single elements of a reference genome. Alignment is concerned with finding relationships between consecutive elements of an input string and substructures in the reference genome. A mapping score is defined as the score achieved by looking up two bases in a substitution matrix.  
\begin{defn}[Mapping score]
  \label{def:mapping_score}
  A score produced by mapping two characters $b_1, b_2 \in \{A, C, G, T\}$ against a substitution matrix contained in a scoring schema. Referenced by $mappingScore(b_1, b_2)$.
\end{defn}
\noindent
For linear strings mapping is easy. Every string has the same underlying coordinate system, represented by the positions of the characters, and two elements from two separate sequences are either in the same position or they are not. If they are not the difference in position can be derived from the difference between the indexes. Because the indexes of a graph has only one property, uniqueness, they do not hold the intrinsic value of describing relationships between vertices. Any mapping system which uses fixed coordinates would face problems when dealing with a fluent graph able to merge in new information, as the internal relations are bound to change. In de Bruijn graphs the problem is solved by moving the mappable quality away from positions and into the data: For any possible k-mer there either is a corresponding vertice or there is not. In sequence graphs, where nucleotides are the most basic information, there exists an equal number of identically scoring positions for every base as there are vertices containing that vertice in the graph.\\
\par\noindent
Paten et al.\cite{mapping_to_a_reference_genome_structure} introduce the concept of \textit{context-based mapping} as a solution to the mapping problem when the reference is modeled as a graph. Context-based mapping is an approach where a vertice is identified by the surrounding environment in the graph. More technically a vertice has a set of \textit{contexts} which are paths that pass through the vertice. Because these paths are linear and passes through vertices containing characters, the contexts can be treated as text strings. There are two concrete examples of approaches presented in the article: The \textit{general left-right exact match mapping scheme} and the \textit{central exact match mapping scheme}. The key words left-right and central refer to how a vertice defines it's contexts based on the surrondings. The former defines separate contexts for incoming and outcoming paths whereas the latter defines the vertice as a center of a path where the differences of the lengths of the two contexts are minimized. A  \textit{balanced central exact match mapping scheme} is a special case of the latter where both contexts are the same length, and the vertice thus is the center of a k-mer. This is a concept closely related to de Bruijn graphs.\\
\par\noindent
Both of the examples use the word \textit{exact} in their definitions. The term refers to the fact that every context is \textit{unique} to a single vertice which means every possible context either maps unambiguously to a single vertice or does not map at all. Because the graphs have the possibility of branching a vertice can have several contexts contained in \textit{context sets}. Because every context is unique a collection of such will also be unique, which means context-based mapping leads to a two-way unique mapping schema. This is an even strong notion of mappability than positions is strings, as a character of a string does not necessarily map uniquely back to its position. This strong notion has a drawback: There exists situations where a vertice does not have a unique context which yields it unmappable.
\subsection{Alignment}
\textcolor{red}{Intro}
\subsubsection{Dynamic programming on graphs}
\label{sec:po_msa}
\textcolor{red}{PO-MSA}
\subsubsection{Context-based alignment}
\textcolor{red}{Canonical, Stable, General Mapping using Context Schemes}
\clearpage
\section{Techniques and tools}
\subsection{Dynamic programming}
\label{sec:dynamic_programming}
\textit{Dynamic programming} (DP) is a problem-solving technique where a problem instance is solved by combining the results of smaller subproblems. DP is similar to recursion in that every instance is solved by a \textit{recurrence relation} (Equation \ref{eq:ed_recurrence_relation}) which recurses on smaller and smaller problems until a \textit{base case} is found. A base case represent the bottom of the recursion and is a value which can easily be computed without further lookups. The main difference between recursion and DP is that the latter usually stores its intermediate results to allow for fast lookups for reoccuring instances. DP is often used as an approach for optimization problems in order to minimize computational complexity while giving a guarantee for optimal results \cite[Chapter 9]{algorithms_sequential_parallell_and_distributed}.
\begin{wrapfigure}{r}{0.67\textwidth}
  \begin{mdframed}
    \begin{center}
      \begin{tabularx}{\textwidth}{ccccccccccc}
        &&a&l&g&o&r&i&t&h&m \\ \cline{2-11}
         &\multicolumn{1}{|c|}{0}&1&\multicolumn{1}{|c|}{2}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&7&\multicolumn{1}{|c|}{8}&\multicolumn{1}{c|}{9}\\ \cline{2-11}
        l &\multicolumn{1}{|c|}{1}&1&\multicolumn{1}{|c|}{1}&2&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
        o &\multicolumn{1}{|c|}{2}&2&\multicolumn{1}{|c|}{2}&2&\multicolumn{1}{|c|}{2}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&\multicolumn{1}{c|}{7}\\ \cline{2-11}
        g &\multicolumn{1}{|c|}{3}&3&\multicolumn{1}{|c|}{3}&2&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
        a &\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&6&\multicolumn{1}{|c|}{7}&\multicolumn{1}{c|}{8}\\ \cline{2-11}
        r &\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{4}&4&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&5&\multicolumn{1}{|c|}{6}&\multicolumn{1}{c|}{7}\\ \cline{2-11}
        i &\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{5}&5&\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{3}&4&\multicolumn{1}{|c|}{5}&\multicolumn{1}{c|}{6}\\ \cline{2-11}
        t &\multicolumn{1}{|c|}{7}&6&\multicolumn{1}{|c|}{6}&6&\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{4}&3&\multicolumn{1}{|c|}{4}&\multicolumn{1}{c|}{5}\\ \cline{2-11}
        h &\multicolumn{1}{|c|}{8}&7&\multicolumn{1}{|c|}{7}&7&\multicolumn{1}{|c|}{7}&6&\multicolumn{1}{|c|}{5}&4&\multicolumn{1}{|c|}{3}&\multicolumn{1}{c|}{4}\\ \cline{2-11}
        m &\multicolumn{1}{|c|}{9}&8&\multicolumn{1}{|c|}{8}&8&\multicolumn{1}{|c|}{8}&7&\multicolumn{1}{|c|}{6}&5&\multicolumn{1}{|c|}{4}&\multicolumn{1}{c|}{3}\\ \cline{2-11}
      \end{tabularx}
    \end{center}
  \end{mdframed}
  \caption{The 2-dimensional array used for solving the edit distance problem for the strings S=``algorithm'' and P=``logarithm'' (Note: This follows regular ED scoring where every operation is penalized +1)}
  \label{fig:edit_distance_array}
\end{wrapfigure}
A problem which is typically solved by dynamic programming is the previously mentioned edit distance problem which utilizes a 2-dimensional array to store the computed values (Fig. \ref{fig:edit_distance_array}).For two strings $S$ and $P$, every index $[i,j]$ in the edit distance table represents the problem instance of the strings $S[0:i],P[0:j]$. The base cases can be seen in the first row and column. There are often dropped from the table itself due to the simple nature of their computations. The remainder of the table is filled out with the following recurrence relation:
\begin{equation}
  D[i,j] = min
  \begin{cases}
    D[i-1,j] + 1\\
    D[i,j-1] + 1\\
    D[i-1,j-1] + score(S[i], P[j])
  \end{cases}
  \label{eq:ed_recurrence_relation}
\end{equation}
where $score(x, y)$ is an inverse equality function. The score for the entire problem instance can be found in the cell with the highest indexes in the bottom right corner.\\
\par\noindent
There are two separate ways of using Dynamic Programming. A \textit{bottom-up} approach starts at the smallest cases and computes everything until it reaches the actual given problem instances. This corresponds to starting in the top left corner of the edit distance array and computing the cells iteratively moving downwards to the right. A \textit{top-down} procedure starts at the given problem instance and recursively computes every subproblem that is needed. This means starting in the bottom right corner of the 2-dimensional array and recursing upwards to the right. For the edit distance problem the choice of approach bears no big significance as every cell has to be computed either way, but there are problems where using top-down can avoid some computations which are irrelevant to the final result. The latter can also be efficient for heuristical methods where an area of the search space can be overlooked.
\subsection{Implementing graphs}
\subsection{Suffix trees}
A \textit{suffix trie} is a special tree constructed for specifically for strings of text, containing vertices representing characters (Fig. \ref{fig:suffix_trie}). Every suffix of a string has a corresponding leaf vertice, where the vertices along path from the root to the vertice contains the characters in the suffix. From this it follows that every substring has a matching path starting in the root node. A \textit{suffix tree}, or \textit{compressed suffix trie}, is a suffix trie in which every linear path is compressed into a single vertice (Fig. \ref{fig:suffix_tree}). Suffix trees can easily be extended to hold collections of strings\cite[Chapter 20]{algorithms_sequential_parallell_and_distributed}. An elementary solution has a space complexity of $O(s)$, where $s$ is the length of the string (or the total length of all strings if the tree is built from a collection), and a string of length $m$ can be looked up in $O(km)$ time for an alphabet of size $k$\cite[Section 20.6.1]{algorithms_sequential_parallell_and_distributed}\\
\begin{figure}[b]
  \begin{subfigure}[t]{0.49\textwidth}
    \begin{mdframed}
      \begin{center}
        \begin{tikzpicture}
          \node[state,scale=0.8] (q0) {};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q0] (q1) {$a$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q0] (q2) {$n$};
          \node[state,scale=0.8] [left=0.25cm of q1] (q3) {$b$};
          \node[state,scale=0.8] [right=0.25cm of q2] (q4) {$s$};
          \node[state,scale=0.8] [below left=0.6 and -0.05cm of q3] (q5) {$a$};
          \node[state,scale=0.8] [below left=0.6 and -0.05cm of q1] (q6) {$n$};
          \node[state,scale=0.8] [below right=0.6 and -0.05cm of q1] (q7) {$s$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q2] (q8) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q5] (q9) {$n$};
          \node[state,scale=0.8] [below=0.36cm of q6] (q10) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q8] (q11) {$n$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q8] (q12) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q9] (q13) {$a$};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q10] (q14) {$n$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q10] (q15) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q11] (q16) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q13] (q17) {$n$};
          \node[state,scale=0.8] [below=0.36cm of q14] (q18) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q16] (q19) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q17] (q20) {$a$};
          \node[state,scale=0.8] [below=0.36cm of q18] (q21) {$s$};
          \node[state,scale=0.8] [below=0.36cm of q20] (q22) {$s$};

          \path 
          (q0) edge node {} (q1)
          edge node {} (q2)
          edge node {} (q3)
          edge node {} (q4)
          (q3) edge node {} (q5)
          (q1) edge node {} (q6)
          edge node {} (q7)
          (q2) edge node {} (q8)
          (q5) edge node {} (q9)
          (q6) edge node {} (q10)
          (q8) edge node {} (q11)
          edge node {} (q12)
          (q9) edge node {} (q13)
          (q10) edge node {} (q14)
          edge node {} (q15)
          (q11) edge node {} (q16)
          (q13) edge node {} (q17)
          (q14) edge node {} (q18)
          (q16) edge node {} (q19)
          (q17) edge node {} (q20)
          (q18) edge node {} (q21)
          (q20) edge node {} (q22);
        \end{tikzpicture}
      \end{center}
    \end{mdframed}
    \caption{}
    \label{fig:suffix_trie}
  \end{subfigure}
  \begin{subfigure}[t]{0.49\textwidth}
    \begin{mdframed}
      \begin{center}
        \begin{tikzpicture}
          \node[state,scale=0.8] (q0) {};
          \node[state,scale=0.8] [below left=0.6cm and -0.05cm of q0] (q1) {$a$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [left=0.25cm of q1] (q3) {$bananas$};
          \node[state,scale=0.8] (q3) [below right=0.6cm and -0.05cm of q0] (q4) {$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [right=0.5cm of q4] (q2) {$na$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q1] (q5) {$na$};
          \node[state,scale=0.8] (q6) [below right=0.6cm and -0.05cm of q1]{$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q2] (q7) {$nas$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q2] (q8) {$s$};
          \node[rectangle,draw,inner sep=0.2cm,scale=0.8] [below left=0.67cm and -0.05cm of q5] (q9) {$nas$};
          \node[state,scale=0.8] [below right=0.6cm and -0.05cm of q5] (q10) {$s$};

          \path
          (q0) edge node {} (q1)
          edge node {} (q2)
          edge node {} (q3)
          edge node {} (q4)
          (q1) edge node {} (q5)
          edge node {} (q6)
          (q2) edge node {} (q7)
          edge node {} (q8)
          (q5) edge node {} (q9)
          edge node {} (q10);
        \end{tikzpicture}
      \end{center}
    \end{mdframed}
    \caption{}
    \label{fig:suffix_tree}
  \end{subfigure}
  \caption{The suffix tree and suffix trie of the string ``bananas''}
  \label{fig:suffix_trees}
\end{figure}
\par\noindent
\textcolor{red}{A Block-sorting Lossless Data Compression Algorithm}
\subsection{Visualization of graphs: The dot-format}
\end{document}



















